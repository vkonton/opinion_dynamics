\section{An Update Rule with Fast Convergence Rate}\label{s:cc_convergence}

We already discussed that the reason that opinion dependent dynamics suffer slow
convergence is that the update rule depends only on the expressed opinions.
Based on works for asynchronous distributed minimization algorithms \cite{BT97,CC16},
we provide an update rule showing that information about the
graph $G$ combined with agents that do not act selfishly can restore the
fast convergence rate.
Our update rule, depends not only on the expressed opinions of the
neighbors that an agent $i$ meets but also on the $i$-th row of matrix $P$.
In update rule (\ref{alg:cc_upper}), each agent stores the
\emph{most recent} opinions of the random neighbors that she meets in an array
and then updates her opinion according to their weighted sum
(each agent knows row $i$ of $P$). For a given instance
$I=(P,s,\alpha)$ we call the produced dynamics \emph{Row Dependent dynamics}
and it is defined in Dynamics~\ref{alg:influence_dependent}.

The problem with this approach is that the opinions of the neighbors
that she keeps in her array are \emph{outdated}, i.e. the opinion of
a neighbor of agent $i$ has changed since their last meeting.
The good news are that as long as this outdatedness
is bounded we can still achieve fast convergence to the
equilibrium.  By bounded outdatedness we mean that there exists a
number of rounds $B$ such that all agents have met all their neighbors
at least once from $t-B$ to $t$. The latter is formally stated in
Lemma~\ref{l:outdatedness_induction} and its proof can be found
Appendix~\ref{app:s:cc_convergence}.

\begin{remark}
  %It is necessary that each agent $i$ \enquote{knows} the row $i$ of matrix $P$ for
  %this update rule to work.
  Update rule~(\ref{alg:cc_upper}), apart from the opinions
  and the indices of the neighbors that an agent meets,
  also depends on the the exact values of the weights $p_{ij}$ and that is
  why \emph{Row Dependent dynamics} converge fast. We mention that the lower bound of
  Section~\ref{s:lower_bound} still holds even if the agents also use the indices
  of the neighbors that they meet to update their opinion, since
  Lemma~\ref{l:reduction} can be easily modified to
  cover this case. The latter implies that any update rule that
  ensures fast convergence must require that each agent
  $i$ is \emph{aware} of the $i$-th row of matrix $P$.

\end{remark}
\vspace{-5mm}
\begin{algorithm*}
  \caption{Row Dependent dynamics}
  \label{alg:influence_dependent}
  \begin{algorithmic}[1]
    \STATE Initially $x_i(0) = s_i$ for all agent $i$.
    \STATE Each agent $i$ keeps an array $M_i$ of length $|N_i|$,
    randomly initialized.
    \STATE At round $t\geq 0$ each agent $i$:
    \bindent
    \STATE Meets neighbor with index $W_i^t$, $\Prob{W_i^t=j}=p_{ij}$.
    \STATE Suffers cost \((1-\alpha_i) (x_i(t) - x_{W_i^t}(t))^2 + a_i (x_i(t) - s_i)^2\)
    and learns $(x_{W_i^t}(t),W_i^t)$.
    \STATE Updates her array $M_i$ and opinion:
    $
    M_i[W_i^t] \gets x_{W_i^t}(t),\quad
    x_i(t+1) = (1-\alpha_i)\sum_{j \in N_i} p_{ij} M_i[j] + \alpha_i s_i
    $
    \inlineequation[alg:cc_upper]{}
    \eindent
  \end{algorithmic}
\end{algorithm*}

%In \cite{BT97}, they show a convergence rate guarantee for
%\ref{alg:cc_upper} assuming that there exists a such a window $B$.
%In the  following we briefly summarize their result.  For completeness we
%give here a prove tailored for our purposes.
%Using a simple induction we get that bounded outdatedness
%preserves the fast convergence.  Its simple proof can be found in
\begin{replemma}{l:outdatedness_induction}
  Let $\rho = \min_i a_i$, and $\pi_{ij}(t)$ be the most recent round
  before round $t$, that agent $i$ met her neighbor $j$.
  If for all $t\geq B$, $t-B \leq \pi_{ij}(t)$ then, for
  all $t \geq k B$,
  \(\norm{\infty}{x(t) - x^*} \leq (1-\rho)^k\).
\end{replemma}

In our randomized setting there does not exist a fixed length window $B$
that satisfies the requirements of Lemma~\ref{l:outdatedness_induction}.
However we can select a length value such that the requirements hold with high probability.
To do this observe that agent $i$ simply needs to wait to meet the neighbor
$j$ with the smallest weight $p_{ij}$. Therefore, after
$\log(1/\delta)/\min_{j} p_{ij}$ rounds we have that with probability at least
$1-\delta$ agent $i$ met all her neighbors at least once.
Since we want this to be true for all agents
we shall roughly take $B = 1/\min_{p_{ij} > 0} {p_{ij}}$.
In Section~\ref{app:s:cc_convergence} of the Appendix we give the detailed
argument that leads to the Theorem~\ref{t:exponential_update_rule},
showing that the convergence rate of update rule (\ref{alg:cc_upper}) is fast.

\begin{reptheorem}{t:exponential_update_rule}
  Let $I = (P,s, \alpha)$ be an instance of the opinion formation
  game of Definition~\ref{d:random_game} with equilibrium
  $x^* \in [0,1]^n$ and let $\rho = \min_{i \in V} a_i$.
  The opinion vector $x(t)\in[0,1]^n$ produced by
  update rule~(\ref{alg:cc_upper}) after $t$ rounds satisfies
  \(
    \Exp{\norm{\infty}{x(t) - x^*}}
    \leq
    2\exp(- \rho  \min_{ij} p_{ij} \sqrt{t}/(4\ln(nt)) ).
  \)
\end{reptheorem}
