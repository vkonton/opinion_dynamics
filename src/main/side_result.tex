\section{An Update Rule with Exponential Convergence Rate}\label{s:cc_convergence}

We already discussed that the reason that opinion dependent dynamics suffer slow
convergence is that the update rule depends only on the expressed opinions.
Based on works for distributed convex optimization \cite{BT97},
we provide an update rule showing that information about the
graph $G$ combined with agents that do not act selfishly can restore the
exponential convergence rate.
Our update rule, depends not only on the expressed opinions of the
agents but also on their indices and matrix $P$.
Having this knowledge, one could try to come up with an
update rule resembling the original update rule of the FJ model.
In update rule \ref{alg:cc_upper}, each agent could store the
\emph{most recent} opinions of the random neighbors that she meets in an array
and then update her
opinion according to their weighted sum (each agent knows row $i$ of $P$).
The problem with this approach is that the opinions of the neighbors
that she keeps in her array are \emph{outdated}, i.e. the opinion of
neighbor of agent $i$ is different than what she expressed in their
last meeting.  The good news are that as long as this outdatedness
is bounded we can still achieve exponential convergence to the
equilibrium.  By bounded outdatedness we mean that there exists a
number of rounds $B$ such that all agents have met all their neighbors
at least once from $t$ to $t+B$.
\begin{remark}
It is necessary to know the matrix $P$ in order for this
update rule to work. We first observe that the lower bound of
Section~\ref{s:lower_bound} also holds in case the algorithm learns the index
of the chosen neighbor. The reason is that the reduction involves only two neighbors
with different opinions, so they are distinguishable.
Therefore, if we tried to learn $P$ by observing the frequencies
of the indices of the neighbors and run update rule \ref{alg:cc_upper}
with the empirical frequencies instead of the $p_{ij}$, our lower bound
ensures that the rate of convergence would not be $O(1/t^{1+c})$ for any $c>0$.
Intuitively, if we know $P$ then the algorithm converges exponentially,
since the slow part of the process is learning the probabilities $p_{ij}$
precisely.
\end{remark}
\vspace{-5mm}
\begin{algorithm*}
  \caption{Asynchronous Update Rule}
  \label{alg:cc_upper}
  \begin{algorithmic}[1]
    \STATE Initially $x_i(0) = s_i$ for all agent $i$.
    \STATE Each agent $i$ keeps an array $M_i$ of length $|N_i|$,
    randomly initialized.
    \STATE At round $t\geq 0$ each agent $i$:
    \bindent
    \STATE Meets neighbor with index $W_i^t$, $\Prob{W_i^t=j}=p_{ij}$.
    \STATE Suffers cost \((1-\alpha_i) (x_i(t) - x_{W_i^t}(t))^2 + a_i (x_i(t) - s_i)^2\)
    and learns $(x_{W_i^t}(t),W_i^t)$.
    \STATE Updates her array $M_i$ and opinion as follows:
      \bindent
      \STATE $M_i[W_i^t] \gets x_{W_i^t}(t)$.
      \STATE $x_i(t+1) = (1-\alpha_i)\sum_{j \in N_i} p_{ij} M_i[j] + \alpha_is_i$
      \eindent
    \eindent
  \end{algorithmic}
\end{algorithm*}

In \cite{BT97}, they show a convergence rate guarantee for
\ref{alg:cc_upper} assuming that there exists a such a window $B$.
In the  following we briefly summarize their result.  For completeness we
give here a prove tailored for our purposes.
Using a simple induction we get that bounded outdatedness
preserves the exponential convergence.  Its simple proof can be found in
Appendix~\ref{app:s:cc_convergence}.

\begin{replemma}{l:outdatedness_induction}
  Let $\rho = \min_i a_i$, and $\pi_{ij}(t) \in \N$ be the most recent round
  before round $t$, that agent $i$ met agent $j$.
  If for all $t\geq B$, $t-B \leq \pi_{ij}(t) \leq t-1$ then, for
  all $t \geq k B$,
  \(\norm{\infty}{x(t) - x^*} \leq (1-\rho)^k\).
\end{replemma}

In our randomized setting there does not exist fixed length window is
not true but we can easily adapt this to hold with high probability.
To do this observe that agent $i$ simply needs to wait to meet the neighbor
$j$ with the smallest weight $p_{ij}$. Therefore, after
$\log(1/\delta)/\min_{j} p_{ij}$ rounds we have that with probability at least
$1-\delta$ agent $i$ met all her neighbors at least once.
Since we want this to be true for all agents
we shall roughly take $B = 1/\min_{p_{ij} > 0} {p_{ij}}$.
In Section~\ref{app:s:cc_convergence} of the Appendix we give the detailed
argument that leads to the Theorem~\ref{t:exponential_update_rule},
showing that the convergence rate of update rule \ref{alg:cc_upper} is exponential.

\begin{reptheorem}{t:exponential_update_rule}
  Let $I = (P,s, \alpha)$ be an instance of the opinion formation
  game of Definition~\ref{d:random_game} with equilibrium
  $x^* \in [0,1]^n$ and let $\rho = \min_{i \in V} a_i$.
  The opinion vector $x(t)\in[0,1]^n$ produced by
  update rule~(\ref{alg:cc_upper}) after $t$ rounds satisfies
  \[
    \Exp{\norm{\infty}{x(t) - x^*}}
    \leq
    2\exp \lp(- \rho  \min_{ij} p_{ij} \frac{\sqrt{t}}{4\ln(nt)} \rp).
  \]
\end{reptheorem}
