\section{A Graph Aware Update Rule}\label{s:graph_aware}

In Section~\ref{s:lower_bound} we saw that in our \emph{imperfect information}
for any no-regret algorithm $\mcal{A}$ there exists a graph $G$ such that the
corresponding dynamics needs \( \poly(1/\eps) \) rounds to achieve error
$\eps$.  However, in the \emph{perfect information} FJ-model there exists a
simple update rule that requires only $\log(1/\eps)$ rounds.  Notice that our
lower crucially depends on both the fact that $\mcal{A}$ is no-regret. At this
point, a natural question is whether, this exponential gap is a generic
restriction of imperfect information model?  We answer question in the
negative. More precisely the reason that no-regret dynamics suffer slow
convergence is that the update rule depends only on the expressed opinions. In
this section we show that update rules that also depend on the graph $G$ can
achieve exponentially fast convergence.  Perhaps surprisingly, we show that our
update rule only depends on the expressed opinions, the number of neighbors of
each agent and the maximum degree $d$ of $G$.  The latter is interesting
because information about the graph $G$ combined with agents that do not act
selfishly can restore the exponential convergence rate.

The main idea of the protocol is straightforward: to counterbalance the
imperfect information the agents spend some rounds just to simulate one round
of the original FJ-model. To do this, they agree to stop updating their
expressed opinion for a large enough window of rounds so that everybody learns,
with high probability, \emph{exactly} the average of the opinions of their
neighbors.  Following the ideas of Section~\ref{s:fictitious_convergence} an
agent could try to learn the average of the opinions of her neighbors by just
averaging the opinions that she gets in this window.  Unfortunately this would
again result in a $\poly(1/\eps)$-round protocol.  However this can be fixed by
using the additional knowledge of the number of agents. Precisely, each agent
$i$ keeps an array with the frequencies that she observed. But there is a
catch, when the window ends, she rounds each frequency to the closest multiple
of $1/d_i$, where $d_i$ is the number of neighbors of agent $i$. To see that
this works, first notice that if all agents stop updating their opinions for
$d$ rounds, the problem of learning the frequencies of the different opinions
is equivalent to the problem of learning the probability mass function of a
discrete distribution with support at most $d$, since the number of different
opinions that an agents sees is at most equal to the max degree of the graph.
Using a VC-dimension argument one shows that with $d^2 \log d$ samples each agent
knows the frequencies within error smaller than $1/d$ with constant
probability (which can be trivially amplified by repeating the procedure).
Now, using the fact that the frequencies of the opinions of agent $i$ can
only be multiples of $1/d_i$ we can round the estimated frequencies to the
closest multiple of $1/d_i$ to get the true frequencies and use them to get
the exact average of the opinions of the neighbors.
We next state a version of the standard VC-Inequality that we will use
in our argument.  Let $P$ be a discrete distribution over $[d]$, and let
$S_1, \ldots, S_t$ be $t$ i.i.d samples drawn from $P$, i.e.
$(S_1, \ldots, S_t) \sim P^t$.  The empirical distribution $\hat{P}_t$ is the
following estimator of the density of $P$.
\begin{equation}\label{eq:empirical_distribution}
  \hat{P}_N(A) = \frac{\sum_{i=1}^N \1{S_i \in A}}{N},
\end{equation}
where $A \subseteq [d]$. In words, $\hat{P}_N$ simply counts
how many times the value $i$ appeared in the samples $S_1, \ldots S_N$.
We will use the following version of the classical result of Vapnik and
Chervonenkis.
\begin{lemma}\label{l:vc_inequality}
  Let $\mcal{A}$ be a collection of subsets of $\{0,\ldots, d\}$ and
  Let $S_{\mcal{A}}(N)$ be the Vapnik-Chervonenkis shatter coefficient, defined
  by
  \[
    S_{\mcal{A}(N)} = \max_{x_1,\ldots, x_t \in [d]}
    \lp| \{ \{x_1, \ldots, x_t\} \cap A : A \in \mcal{A} \} \rp|.
  \]
  Then
  \[
    \Expnew{P^N}{\max_{A \in \mcal{A}} \lp| \hat{P}_t(A) - P(A) \rp|}
    \leq 2 \sqrt{\frac{\log{2 S_{\mcal{A}}(N)}}{N}}
  \]
\end{lemma}

\begin{algorithm}
  \caption{Graph Aware Update Rule}
  \label{alg:frequencies}
  \begin{algorithmic}[1]
    \State $x_i(0) \gets s_i$.
    \For{$l = 1, \ldots,\ln(1/\eps))$}
    \State Keep a map $h$ from $[0,1]$ to $[d_i]$,
    an array of counters $A$ of length $d_i$ and an array $B$ of length
    $M_1$.
    \State $M_1 = O(\ln(n/\eps))$, $M_2 = O(d^2 \ln(d))$

    \For{$j = 1, \ldots, M_1$}
    \For{$k = 1, \ldots, M_2$}

    \State Get the opinion $X_i$ of a random neighbor.
    \If{$X_i$ is not in $h$}
    \State Insert $X_i$ to $h$.
    \Else
    \State $A(h(X_i)) \gets A(h(X_i)) +1$.

  \EndIf
  \State $t \gets t+1$
\EndFor
\State Divide all entries of $A$ by $M_2$.  \label{alg:line:counters}
\State Round all entries of $h$ to the closest multiple of $1/d$.
\State $B(j) = \sum_{i=1}^{d_i} A(i)$.
\EndFor
\State $x_i(t) \gets \maj_{j} B(j)$.
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{theorem}
  Let $I = (G(V,E) ,s, a)$ be an instance of the opinion formation
  game of Definition~\ref{d:random_payoff_game} with $a > 1/2$.
  Let $d$ be the maximum degree of the graph $G$ and $n = |V|$.
  There exists an update rule
  after $O(d^2 \log^2 n \log^2(1/\eps))$ rounds
  achieves expected error
  \(
    \Exp{\norm{\infty}{x_t- x^*}}
    \leq \eps.
  \)
\end{theorem}
\begin{proof}
  According to the update rule~\ref{alg:frequencies}
  all agents fix their opinions $x_i(t)$ for $M_1 \times M_2$ rounds.
  To estimate the sum of the opinions each agent estimates the
  frequencies $k_j/d_i$. Since the neighbors have at most $d_i$
  different opinions we can map the opinions to natural
  numbers in $[d_i]$.  At each round the agent gets the opinion
  of a random neighbor and therefore the samples $X_i$ that she
  observes are drawn from a discrete distribution $P$ supported on
  $[d_i]$.
  If $k_j$ be the (absolute) frequency of the opinion $j$
  namely the number of neighbors that express $j$ as their
  opinion, then the probability $P(j)$ of opinion $j$ is
  $k_j/d_i$.  To learn the probabilities $P(j)$ using samples from $P$,
  we let $\mcal{A} = \{\{1\},\{2\},\ldots, \{d_i\}\}$ and
  use Lemma~\ref{l:vc_inequality} to get that
  \[
    \Expnew{P^m}{\max_{j \in [d_i]} \lp| \hat{P}_m(j) - P(j) \rp|}
    \leq 2 \sqrt{\frac{\log{2 d_i}}{m}},
  \]
  since $S_{\mcal{A}} \leq d_i$. Therefore, an agent can draw
  $m = 100 d^2 \log(2 d)$ to learn the frequencies $k_j/d_i$
  within expected error $1/(5 d)$.
  Notice now that the array $A$ after line~\ref{alg:line:counters}
  corresponds to the empirical distribution of
  equation~(\ref{eq:empirical_distribution}).
  Notice that if the agents have estimations of the frequencies $k_j/d_i$
  with error smaller than $1/d$, then by rounding them to the closest
  multiple of $1/d_i$ they learn the frequencies exactly.
  By Markov's inequality we have that with probability at least $4/5$ the
  rounded frequencies are exactly correct.
  By standard Chernoff bounds we have that if the agents repeat the
  above procedure $\ln(1/\delta)$ times and keep the most frequent of the
  answers $B(j)$, then they will obtain the correct answer with
  probability at least $1-\delta$. We know that, having computed
  the \emph{exact} average of the opinions of the neighbors $Ο(\log(1/\eps))$
  rounds are enough to achieve error $\eps$.
  Since we need all nodes to succeed at computing the exact averages for
  $Ο(\log(1/\eps))$ rounds, from the union bound we get that for
  $\delta < \frac{\eps}{n \ln(1/\eps)}$, with
  probability at least $1-\eps$ the error is at most $\eps$.
  Finally, from the law of total expectation, after
  $T = O(d^2 \log d \log(\eps) (\log(n/\eps) + \log \log(1/\eps))$ rounds
  the expected error is
  $\Exp{\norm{\infty}{x_T - x^*}} = (1-\eps) \eps + \eps \leq 2 \eps$.
\end{proof}
