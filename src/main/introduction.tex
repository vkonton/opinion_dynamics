\section{Introduction}
The formation and dynamics of opinions are an important aspect in modern
society and have been studied extensively for decades (see e.g., \cite{Jackson}).
Opinion formation is based on information exchange, between socially
connected people (e.g., family, friends, colleagues) who interact often
and affect each other's opinion. Moreover, opinion
formation is often \emph{dynamic} in the sense that discussions and
interactions lead to changes in the expressed opinions. With the
advent of the internet and social media the dynamic aspects of
opinion formation have become ever more dominant. To capture opinion formation
on a formal level, several models have been proposed
(see e.g., \cite{DeGroot,FJ90,HK,BKO11} for
continuous opinions and \cite{FGV12,YOASS13,BFM16} for discrete ones).
A common assumption, that dates back to DeGroot \cite{DeGroot}, is
that opinions evolve through a form of repeated averaging of
information collected from the agent social neighborhoods.

Our work builds on the model
proposed by Friedkin and Johnsen \cite{FJ90}.
The FJ model is a variation on the DeGroot model
that captures the fact consensus on the opinions
of a social group is not generally reached.
According to FJ-model there exists a set of $n$ agents.
Each agent $i$ holds an internal opinion $s_i\in [0,1]$, which is private and
invariant over time and a public opinion $x_i \in [0,1]$.
Initially, agents start with their internal opinion and at
each round $t\geq1$, update their public opinion
$x_i(t)$ to a weighted average of public opinion of
their social neighbors and their internal opinion,
%
\begin{equation}\label{eq:FJ_model}
  x_i(t)= \frac{\sum_{j\neq i}w_{ij}x_j(t-1)
    + w_{ii}s_i}{\sum_{j\neq i}w_{ij}+w_{ii}}
\end{equation}
%
where the weights $w_{ij}\geq 0$ quantify the influence between
the agents and $w_{ii}>0$ the self confidence of the agents
towards their internal belief.

The FJ model is one of most influential models for opinion formation.
Its has a very simple update rule, consisting it plausible
for modeling natural behavior and
its basic assumptions are aligned with empirical
findings on the way opinions are formed \cite{AFH05,K47}.
At the same time, it admits a unique equilibrium point
$x^* \in [0,1]^n$ to which it converges exponentially fast \cite{GS14}.
The FJ-model has also been studied under a game theoretic
view point. Bindel et al. considered its update rule
as the minimizer of a quadratic disagreement cost function
and based on it they defined the following one shot
opinion formation game \cite{BKO11}. The strategy of each agent $i$ is
her public opinion $x_i$, incurring her a
disagreement cost
%
\begin{equation}\label{eq:BKO_cost}
  C_i(x_i,x_{-i})=
  \sum_{j \neq i}w_{ij} (x_i-x_j)^2 + w_{ii}(x_i-s_i)^2
\end{equation}
%
Note that the FJ model is the \emph{simultaneous best response dynamics}
in the repeated version of this one shot game and that the Nash equilibrium
of the above game is $x^*$. In \cite{BKO11} they quantified
the inefficiency of the equilibrium with respect to the total
disagreement cost. Namely, the Price of Anarchy is less than $9/8$
in case $w_{ij}=w_{ji}$.

We remark in \cite{BKO11}, Bindel et al. also introduced an alternative
framework for studying the dynamics of opinions.
Instead of modeling the way opinions evolve
by precise dynamical processes, agents can be considered to repeatedly
play a suitable one shot opinion formation game and update their
opinions so as to minimize their individual disagreement cost.
This framework is much more fruitful since
different angles of the opinion formation process can be easily
captured by suitable one shot games e.g. in \cite{BGM13,EFHS17}
variants of the above opinion formation game were introduced
and the convergence properties of the \emph{best response dynamics}
were studied. This framework also permits that the agents
update their opinions in more abstract ways than
a specific update rule of a precise dynamical process.
For example in the above repeated game, agents instead of
adopting \emph{best response}, could update their opinions according
to a \emph{no-regret} learning algorithm.

\subsection{Motivation and our setting}
The equilibrium point $x^*$ is generally considered
as a good estimation of the final opinions
formed in a social network. For example, Gionis et al. \cite{GTT13}
considered the problem of identifying $k$ agents in an network to set their
internal opinion equal to 1 so as to maximize the sum of the opinions
in the equilibrium point $x^*$ ($\norm{1}{x^*}$). This work belongs to
a recent line of research concerning influence maximization problems
with respect to $x^*$ \cite{GTT13,AKPT18,MMT17}. The reason for modeling
such problems by the equilibrium $x^*$ is evident,
the FJ model is one of the standard models for opinion formation
and it converges exponentially fast to $x^*$.

Our work is motivated by the fact that the FJ model assumes a large amount of
information exchange between the agents. At each round its update rule requires
that every agent learns all the opinions of her social neighbors.  In today's
large social networks where users usually have several hundreds of friends it
is unlikely that they can learn the opinions of all their social neighbors each
day.
In such environments it is far more reasonable to assume that individuals randomly
meet a small subset of their acquaintances and these are the only opinions that
they learn.  Such information exchange constraints consist the FJ model
unsuitable for modeling the opinion formation process in such large networks
and consequently it is doubtful whether $x^*$ captures the limiting behavior
of the opinions. This work ask the following questions:
\begin{question}\label{q:motivation1}
Is the equilibrium $x^*$ an adequate way to model
the final formed opinions in a large social network? Namely, are there
simple variants of the FJ model that require limited information exchange and
imply fast convergence to $x^*$? Can they be justified as natural behavior
for selfish agents under a game-theoretic solution concept?
\end{question}

To capture the fact that in large networks, agents meet a small random subset of
their friends each day, we consider an imperfect-information variant of the
opinion formation game defined in \cite{BKO11}. In equation~(\ref{eq:BKO_cost})
the coefficient $w_{ij}$ measures the influence that $j$ poses on $i$.
Following the common belief that \enquote{we are influenced more by
those we interact more often}, $w_{ij}$ can be interpreted as
a measure on how frequently $i$ meets $j$. In our imperfect-information
variant, each agent $i$ randomly meets an agent $j$ (with respect to her weights)
and experiences disagreement cost based on the distance of their opinions and on
how susceptible is $i$ on her internal opinion. More formally, we consider the
following one shot game.
%
\begin{definition}\label{d:random_game}
  For a given opinion vector $x \in [0,1]^n$, the disagreement cost of agent $i$
  is the random variable $C_i(x_i,x_{-i})$ defined as follows:
  \begin{itemize}
    \item $i$ meets one of her neighbors $j$ with probability
      $p_{ij}= w_{ij}/\sum_{j\in N_i}w_{ij}$
    \item suffers cost $C_i(x_i , x_{-i}) = (1-a_i)(x_i-x_j)^2 + a_i(x_i-s_i)^2$,
      where $\alpha_i = w_i/(\sum_{j\in N_i}w_{ij}+w_i)$
  \end{itemize}
\end{definition}
%
The main difference of the original opinion formation game in \cite{BKO11}
and our variant is that in the first case an opinion vector $x\in [0,1]^n$ defines
\emph{deterministically} the cost $C_i(x)$ of each agent $i$,
whereas in the second it defines a probability distribution on the cost
$C_i(x)$ that $i$ suffers. Notice that the expected
disagreement cost of each agent $i$ (scaled by the constant $\sum_{j\neq i}w_{ij}+w_{ii}$)
is the same as the disagreement cost defined in equation~(\ref{eq:BKO_cost}).
As a result, the Nash equilibrium with respect to the expected cost of the agents,
is the equilibrium point $x^*$.

In order to model the opinion formation process in limited information
exchange environments, we consider that the agents to be engaged in the
above one-shot game. At round $t$, each agent $i$ selects an opinion
$x_i(t)$ and suffers a disagreement cost based on the opinion
of the neighbor that she randomly met. At the end of the round she is
informed only about the opinion of this neighbor and may use this information
to update her opinion. The reduction in information exchange is evident:
At each round each agent learns the opinion of \emph{just one} of her neighbors.
Question~\ref{q:motivation1} now takes the following more concrete form.
\begin{question}\label{q:motivation2}
Can the agents update their opinions according to the
limited information that they receive such that the produced opinion vector
$x(t)$ convergences fast to the equilibrium $x^*$ and the total disagreement cost
that they experience is minimal?
\end{question}

\subsection{Contribution}
We introduce a simple and intuitive update rule that if the agents adopt,
the resulting opinion vector $x(t)$ converges to $x^*$.
Our update rule is a \emph{Follow the Leader algorithm}
meaning that at round $t$, each agent updates her opinion
to the minimizer of total disagreement cost that
she experienced until $t-1$. It also admits a very simple form,
it is just the time average of the opinions that the agent observes.
In section~\ref{s:fictitious_convergence},
we bound its convergence time and we show that in order
to achieve $\eps$ distance from $x^*$, poly($1/\eps$) rounds
are needed. The main technical difficulty lies on stochastic nature
of our process, we deal it with by using elegant concetration arguments.
In section~\ref{s:fictitious_noregret},
we show that this rule ensures \emph{no-regret} to any agent
that adopts it. Namely, the average disagreement cost (that
the agent experiences) per round approaches that
of expressing the best opinion in hindsight. The latter
makes our algorithm a natural behavioral assumption for
agents that selfishly want to minimize their incurred disagreement cost.
The no regret property of our update rule can be easily derived by the
more general results in \cite{HAK07}. However, we present a short a simple
proof that may have some interest. Our results imply that even
if agents are subjected to information exchange constraints, there exists natural
dynamics that converge to equilibrium $x^*$, consisting it
a robust choice for modeling the limiting behavior of the opinions.

In section~\ref{s:lower_bound}, we show
that for any update rule that ensures \emph{no-regret}
to the agents, the resulting opinion vector $x(t)$
cannot converge to $x^*$ faster than polynomially.
We prove the latter for a larger class of update rules,
\emph{opinion dependent update rules} which includes
all the update rules that only depend on the observed
opinions. We deploy a reduction to the existence of
Bernoulli estimators with small error rate and we present
a novel information theoretic argument to rule out their
existence. Interestingly polynomial convergence is not a
generic property our limited information exchange setting.
In Section~\ref{s:cc_convergence}, we present an update rule
that depends on the observed opinions but also on the weights
$w_{ij}$ and converges exponentially fast to $x^*$. Our results
provide a clear and intuitive characterization on the update
rules that can achieve exponential convergence and serve as
an \enquote{algorithmic guide} for future limited information exchange
variants of the FJ model. Moreover they indicate the fundamental reason that
the FJ model converges exponential fast and this has little
to do with the \enquote{large} information exchange
that it requires and much more to do with the fact that
the it uses the values of the weights $w_{ij}$.

\subsection{Related Work}
Apart from the aforementioned results there exists a large amount
of literature concerning the FJ-model.
Many recent works \cite{BGM13,CKO13,BFM16,EFHS17} bound the
inefficiency of equilibrium in variants of opinion formation game
defined in \cite{BKO11}. In \cite{GS14} they bound that the convergence
time of the FJ-model in in special graph topologies.
In \cite{BFM16}, a variant of the opinion formation game in which social
relations depend on the expressed opinions, is studied.
They prove that, the discretized version of the above game admits
a potential function and thus best-response converges to the
Nash equilibrium. Convergence results in other discretized variants of
the FJ-model can be found in \cite{YOASS13,FGV16}. In \cite{FPS16} the convergence
properties of limited information variants of the Heglesmann-Krause model \cite{HK}
and the FJ model, are examined.


Other works, that relate to ours, concern the convergence
properties of dynamics based on no-regret learning algorithms.
In \cite{FV97,FS99,SA00,SALS15} it is proved that in a finite $n$-person
game if each agent updates her mixed strategy according to a no-regret
algorithm the resulting \emph{time-averaged} strategy vector converges to
Coarse Correlated Equilibrium. The convergence properties of no-regret dynamics
for games with infinite strategy spaces were considered in \cite{EMN09}.
They proved that for a large class of games with concave utility function
(socially concave games), the time-averaged strategy vector converges to
the PNE. More recent work investigate a stronger notion of convergence of
no-regret dynamics. In \cite{CHM17} they show that,
in $n$-person finite generic games that admit unique Nash equilibrium,
the strategy vector converges \emph{locally} and exponentially fast
to it. They also provide conditions for \emph{global} convergence.
Our results fit in this line of research since we show that
for a game with \emph{infinite} strategy space, the strategy vector
(and not the time-averaged) converges to the unique Nash equilibrium.

Imperfect information settings have recently received substantial attention
from the scientific community since they provide realistic models for
the practical applications of game theory.  Perfect payoff information
is rare in practise; agents act based on random or noisy past payoff observations.
Kleinberg et al. in \cite{KPT09} treated load-balancing in distributed systems
as a repeated game and analyzed the convergence properties
no-regret online learning algorithms under the \emph{full information assumption}
that each agent learns the load of every machine.
In a subsequent work \cite{KPT11}, the same authors consider the
same problem in a \emph{limited information setting}
(\enquote{bulletin board model})
in which each agent learns the load of just the machine
that served him. In \cite{HCM17,MS17} they examine the convergence
properties of online learning algorithms in case the payoffs observed
by the agents are contaminated with random noise.
Finally, in \cite{BM17} they show stochastic dynamics that
lead to no regret regardless of the amount of noise in the
player's observations and show that in specific zero-sum games
time averages converge to the NE for any noise level.
