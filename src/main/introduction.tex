

%matrix with $P_{ij}=(1-a_i)p_{ij}$
%matrix with $P_{ij}=(1-a_i)p_{ij}$
%Equation~\ref{eq:fj_dynamics}
%can also be written in the following matrix form:

%\begin{equation}\label{eq:fj_matrix_form}
%  x(t) =  P x(t-1) + A s,
%\end{equation}
%where $x(t)=(x_1(t),\ldots,x_n(t))$ is the opinion vector at round $t$, $s$ is the initial opinion vector, $P_{n \times n}$ is a substochastic
%matrix with $P_{ij}=(1-a_i)p_{ij}$ and $A_{n \times n}$ is diagonal matrix with $A_{ii}=\alpha_i$. 


\section{Introduction}

\subsection{Friedkin-Johsen Model and Opinion Formation Games}
In \cite{BKO11} the following \emph{opinion formation game} was introduced.
A weighted directed graph $G(V,E,w)$ is assumed were the vertices stand for the
agent and the acres the social influence among them. Each agent $i \in V$ poses an
\emph{internal opinion} $s_i \in [0,1]$ and a \emph{self confidence coefficient} $w_i>0$. The strategy of
each agent $i$ is the opinion $x_i\in [0,1]$ that she publicly expresses incuring her cost

\begin{equation}\label{eq:BKO_cost}
  C_i(x_i,x_{-i}) = \sum_{j \in N_i}w_{ij}(x_i-x_j)^2 + w_i(x_i -s_i)^2
\end{equation}
\noindent where $N_i$ denotes $i$'s \emph{neighbors} and $w_{ij}$ stands for
the social influence $j$ imposes on $i$. In \cite{BKO11} they proved that 
the above game always admits a \emph{Pure Nash Equilibrium} (PNE) $x^* \in [0,1]^n$
and studied the efficiency of $x^*$. The proved that the \emph{Price of Anarchy}
is less than $9/8$ in case $G$ is bidirectional and $w_{ij}=w_{ji}$. 

In the repeated version of the game defined in \ref{eq:BKO_cost}, at each round $t$ each agent $i$
selects an opinion $x_i(t)$ and then suffers cost $C_i(x_i(t),x_{-i}(t))$. If each agent updates
her opinion to the \emph{best response} of $x(t-1)$,
\begin{equation}\label{eq:FJ_model}
x_i(t) = \text{argmin}_{x \in [0,1]}C_i(x,x_{-i}(t-1))=\frac{\sum_{j \in N_i}w_{ij}x_j(t-1) + w_is_i}{\sum_{j \in N_i}w_{ij} + w_i} 
\end{equation}
\noindent we obtain the Friedkin-Johsen model (FJ-model), which is one of the most influential models in opinion dynamics.
The convergence properties of the FJ-model have been extensively studied. In \cite{GS14} the proved that the $x(t)$ always converges
to the PNE $x^*$ and they provided bounds for the convergence time for various graph topologies. As a result, the 
above \emph{opinion formation game} has some nice algorithmic properties: It always admits a unique equilibrium point $x^*$ and there
exits a simple but most importantly rational update rule for selfish agents that leads the overall system to equilibrium.

\subsection{Opinion Formation Games with Random Payoffs}
Our work is motivated by the fact that the definition of the cost $C_i(x_i,x_{-i})$ 
in~\ref{eq:BKO_cost} implies that agent $i$ meets with of her neighbors. This is more
clear in the update rule \ref{eq:FJ_model}. Each agent in order to compute her best response
has to learn the opinion of all her neighbors. The latter is seems quite unatural in today's
huge social networks (e.g. Facebook, Twitter e.t.c.) in which each agent may have
several hundreds of friends. With this in mind it is far more reasonable to assume 
that each day an agent meets a small subset of her acquaintances and
suffers a cost based on how much she disagrees with them.To capture the above thoughts, 
we introduce the following variant of the opinion formation game with random
payoffs.

\begin{definition}\label{d:random_payoff_game}
  %Let $I$ and instance of the opinion formation game defined in \ref{eq:BKO_cost}. 
  For a given opinion vector $x \in [0,1]^n$, the cost of agent $i$
  is the random variable $C_i(x_i,x_{-i})$ defined as follows:
  \begin{itemize}
    \item $i$ meets one of her neighbors $j$ with probability $p_{ij}= w_{ij}/\sum_{j\in N_i}w_{ij}$
    \item and suffers cost $(1-a_i)\sum_{j \in N_i}(x_i-x_j)^2 + a_i(x_i-s_i)^2$
  \end{itemize}
  where $\alpha_i = w_i/(\sum_{j\in N_i}w_{ij}+w_i)$
\end{definition}
\noindent Our variant has a very natural interpretation: The cost $C_i(x_i,x_{-i})$ in (\ref{eq:BKO_cost})
can be written equivalently 
\begin{equation}\label{eq:BKO11_cost_equivalent}
C_i(x_i,x_{-i}) = W_i\lp( (1-\alpha_i)\sum_{j \in N_i} p_{ij}(x_i-x_j)^2  + \alpha_i(x_i-s_i)^2\rp)
\end{equation}
where $W_i=\sum_{j\in N_i}w_{ij} + w_i$ is a positive constant independent of the opinion vector $x\in [0,1]^n$. As a result, the coefficient $\alpha_i$
measures the reluctancy of agent $i$ to adopt an opinion other than $s_i$, while the $p_{ij}$ can be seen the \emph{real} influence that $j$ poses on $i$.
In Definiton~\ref{d:random_payoff_game}, $p_{ij}$ is frequency that $i$ meets $j$ aligning with the fact that we are influenced more by those we interact
oftently. Equation \ref{eq:BKO11_cost_equivalent} also helps us to establish existence of PNE for the our random payoff variant. 
In our variant the notion of PNE is propertly extended with respect to the expected cost of each agent i.e. $x^* \in [0,1]$ is PNE if and only if
for each agent $i$, $\Exp{C(x_i, x_{-i})} \leq \Exp{C(x_i', x_{-i})}$ for all $x_i' \in [0,1]$. Since 
$\Expnew{}{C_i(x_i,x_{-i})}=(1-\alpha_i)\sum_{j \neq i}p_{ij}(x_i-x_j)^2 + \alpha_i(x_i-s_i)^2$, it follows
from equation~\ref{eq:BKO11_cost_equivalent} that the two games admit the same equilibrium point $x^*$.

%Many recent works (see e.g. \cite{Zhou17}) study games
%with random payoffs, that is agent's $i$ cost ($C_i(x_i,x_{-i})$) is a
%random variable. The random payoff setting can be much more realistic,
%since randomness may naturally occur because of incomplete information, noise
%or other stochastic factors. Motivated by this
%line of research we introduce a random payoff variant of the opinion
%formation game.

\subsection{Our Results and Techniques}

In this work we study the repeated version of the game defined in \ref{d:random_payoff_game}.
At round $t$, each agent $i$ selects an opinion $x_i(t) \in [0,1]$ and then suffers the 
random cost $C_i(x_i(t),x_{-i}(t))$. We are intested in simple and natural update rules
that the agents can adopt such as the resulting opinion vector $x(t)$ converges to $x^*$.
Moreover we require that this update rules are \emph{rational} behavioral assumption for 
selfish agents.

In Section~\ref{s:fictitious_convergence}, we study the convergence properties of $x(t)$ if all agents adopt \emph{fictitious play}
as their update rule. At round $\tau < t$ each agent $i$ experiences disagreement cost 
\[(1-\alpha_i)(x-x_{W_i^\tau}(\tau))^2+\alpha_i(x-s_i)^2 \]where $W_i^\tau$
denotes the agent that $i$ met at round $\tau$. We assume that $i$ selects her opinion 
in order to minimize her aggregated cost until round $t$,
\begin{equation}\label{eq:fictitious_play}
x_i(t) =\argmin_{x \in [0,1]}\sum_{\tau=0}^{t-1}(1-\alpha_i)(x-x_{W_i^\tau}(\tau))^2+\alpha_i(x-s_i)^2 
\end{equation}
\noindent Generally speaking \emph{fictitious play} does not guarantee
convergence to the equilibrium. We prove that \emph{fictitious play} 
converges to equilibrium $x^*$ with the following
rate.
\begin{theorem}\label{t:fictitious_convergence}
  Let $I = (P,s, \alpha)$ be any instance of the opinion formation
  game of Definition~\ref{d:random_payoff_game} with equilibrium
  $x^* \in [0,1]^n$.  The opinion vector $x(t)$ produced by
  update rule~\ref{eq:fictitious_play} after $t$ rounds satisfies
  \[
    \Expnew{}{\norm{\infty}{x(t) - x^*}} \leq
    C \sqrt{\log n}\frac{(\log t)^{2}}{t^{\min(1/2,\rho)}},
  \]
  where $\rho = \min_{i \in V} a_i$ and $C$ is a universal constant.
\end{theorem}
The update rule (\ref{eq:fictitious_play}) guarantees convergence
while vastly reducing the information exchange between the agents
at each round. In (\ref{eq:fictitious_play}) each agent $i$ learns the opinion of only one agent
at each round whereas in the classical FJ-model (\ref{eq:FJ_model}), agent $i$ must
learn the opinions of all her neighbors. In terms of
total communication needed to get within distance $\eps$ of the
equilibrium $x^*$, the update rule (\ref{eq:fictitious_play}) needs
$O(n \log n)$ communication while (\ref{eq:FJ_model}) needs
$O(|E|)$, where $E$ is the number of edges of graph $G$. 
Of course for this difference to be significant we need
each agent to have at least $O(\log n)$ friend (agents $j$ with $p_{ij}>0$). A large social
network like Facebook has approximately $2$ billion users and each user
has usually more that $100$ friends which far more than $\log(2\ 10^9)$.

Apart from converging to the equilibrium, our update rule
(\ref{eq:fictitious_play}) also ensures \emph{no-regret} for the agents.
Having no-regret means that the average cost for each agent $i$
after $T$ rounds is close to the average cost that she would
suffer by expressing any fixed opinion. This is a very important
feature of our update rule because even players that selfishly
will to minimize their incurred cost, could choose to play according
to it. In Section~\ref{s:fictitious_noregret} we show the following
theorem.

\begin{theorem}\label{t:fictitious_noregret}
Let the function $f_i:\reals^2 \mapsto [0,1]$, $f_i(x,b) = (1-\alpha_i)(x-b)^2 + \alpha_i(x-s_i)^2$, where $\alpha_i \in (0,1]$ and $s_i \in [0,1]$.
For any sequence of $\{b_t\}_{t=1}^\infty$ where $b_t \in [0,1]$. If 
\[x_i(t) = \argmin_{x \in [0,1]}\sum_{\tau=0}^{t-1}f_i(x,b_t)\] then for all $t$,
\[\sum_{\tau=1}^tf_i^t(x_i(\tau),b_\tau) \leq \text{min}_{x \in [0,1]}\sum_{\tau=1}^tf_i(x,b_\tau) + \bigOh{\log t}\]
\end{theorem}

Even though our update rule (\ref{eq:fictitious_play}) has the above
desired properties, for a fixed instance $I=(P,s,\alpha)$ it only achieves convergence rate of
$\widetilde{O}(1/t^{\text{min}(\rho,1/2)})$, while the original FJ-model outperforms
our update rule since it achieves convergence rate $O(e^{-\rho t})$ \cite{GS14}.
In section 5 define the \emph{limited information update rules}, that it is the class
of update rules that for each agent $i$: depend only on the opinions that she agent has met
until time $t$ and her $s_i,\alpha_i$ (\emph{fictitious play} in \ref{eq:fictitious_play} 
is clearly an \emph{limited information update rule}).
In section 5, we prove if each agent $i$ updates her 
opinion at round $t$ according to $A$. Then the resulting opinion vector $x_A(t)$ cannot converge to the equilibrium $x^*$ 
with exponential asymptotic rate. More precisely,
\begin{theorem}\label{thm:lower_bound}
If all agents update their opinion according to limited information update rule $A$. Then for any $c>0$ there
exists an instance $I=(P,s,a)$ such that $\Exp{\norm{\infty}{x_A(t) - x^*}} = \Omega(1/t^{1+c})$.
\end{theorem}

To prove this we show that any \emph{limited information update rule} $A$
(that achieves this convergence rate to the equilibrium) implies
the existence of an algorithm that uses i.i.d samples from a Bernoulli random
variable $B(p)$ to estimate its success probability $p$ with the same asymptotic
error rate for all $p \in [0,1]$. Then we prove that such an estimator does not exists (Theorem ??).

In section 6, we investigate whether this lower bound can be extended to more
general class of estimators. We present an update rule that also depends on some parameters of the influence matrix $P$ 
and acheives exponential convergence. The latter implies that \emph{limited information update rules}
is the maximal class that the lower bound applies.

% In section 4, we investigate where a better convergence rate,
% $E[||x(t)-x^*||_{\infty}]$ can be acheived if agent selected another no-regret
% algorithm. More precisely, we investigate the following question, \emph{Is
%   there a no-regret algorithm such that for every instance }
% $I,~E[||x(t)-x^*||_{\infty}] \in \bigOh{\frac{1}{t}}?$  We reduce this question
% to the following question in statistical estimation, \emph{Is there a Bernoulli
%   estimator }$\hat{\theta}$\emph{, such that for all }$q \in [0,1]$, $\lim_{t
%   \rightarrow \infty} t E_q[|\hat{\theta^t} -q|]=0?$  To the best of our
% knowledge this question is not answered in statistics literature. However, we
% use standard tecnhiques for lower bounds in the statistical estimation to prove
% the following theorem.

% \begin{theorem}
%   For any Bernoulli estimator
%   $\hat{\theta}$, for all $[a,b] \subseteq [0,1]:~$ $\lim_{t \rightarrow
%     \infty}t \int_{a}^bE_p[|\hat{\theta^t} -p|]= +\infty$
% \end{theorem}
% This result indicates that the second question and consequently the
% first is very unlike to hold, especially for any reasonable no-regret
% algorithm. We believe that there exists no such algorithm and we leave this
% proof as an open problem.\\

% Finally in section 5, we present an interesting side result. The reason that
% there does not exists a no-regret algorithm, that ensures faster convergence
% rate, is the algorithm's ignorance to the instance $I$ that defines the
% dynamics. More formally, a no-regret algorithm does needs the values $s_i,a_i$
% and $Y_1,\ldots,Y_t$ to determine $x_i(t)$. We find interesting that we design
% a distributed algorithm that uses $s_i,a_i,Y_1,\ldots,Y_t$ and additionally the
% $d_\text{max}$ of $G$ that achieves for every instance $I$ convergence rate,
% $E||x(t)-x^*||_{\infty} \in \bigOh{2^{-\frac{\sqrt{t}}{d^3}}}$.

\subsection{Related Work}
Our work belongs to the line of work studying the seminal Friedkin-Jonhsen
model \cite{FJ90}. Bindel et al. in \cite{BKO11} defined an opinion
formation game based on the FJ-model and bounded the inefficiency
of its equilibrium point with respect to the total disagreement cost.
Subsequent work bounded the inefficiency of its equilibrium in variants
of the latter game \cite{BGM13, EFHS17, CKO13, BFM16}.
In \cite{GS14} they show that the convergence time depends on
the spectral radius of the adjacency matrix of the graph $G$
and provided bounds in special graph topologies.
In \cite{BFM16}, a variant of the opinion formation game in which social
relations depend on the expressed opinions, is studied.
They prove that, the discretized version of the above game admits
a potential function and thus best-response converges to the
Nash equilibrium. Convergence results in other discretized variants of
the FJ-model can be found in \cite{YOASS13, FGV16}.


In \cite{FV97}, \cite{FS99}, \cite{HM00} they prove that in a finite
if each agent updated her mixed strategy according to a no-regret
algorithm the resulting time-averaged distribution converges to
Coarse Correlated Equilibrium. In the same spirit in \cite{BEL06}
they proved that no-regret dynamics converge to NE in the
case of congestion games. Later in \cite{EMN09} they studied no regret
dynamics in games with infinite strategy space. They proved that for a large
class of games with concave utility function (socially concave games), the
time-averaged strategy vector converges to the pure Nash equilibrium.
More recent work investigate a stronger notion of convergence of
no-regret dynamics. In \cite{CHM17} they show that,
in $n$-person finite generic games that admit unique Nash equilibrium,
the strategy vector converges \emph{locally} and exponentially fast
to the PNE. They also provide conditions for \emph{global} convergence.
Our results fit in this line of research since we show that
for a game with \emph{infinite} strategy space, the strategy vector (not the
time-averaged) converges to the unique Nash equilibrium.

