\section{Introduction}
The formation and dynamics of opinions are an important aspect in modern
society and have been studied extensively for decades (see e.g., \cite{Jackson}).
Opinion formation is based on information exchange, between that socially
connected people (e.g., family, friends, colleagues) who interact often
and affect each other's opinion. Moreover, opinion
formation is often \emph{dynamic} in the sense that discussions and
interactions lead to changes in the expressed opinions. With the
advent of the internet and social media the dynamic aspects of
opinion formation have become ever more dominant. To capture opinion formation
on a formal level, several models have been proposed
(see e.g., \cite{DeGroot,FJ90,HK,BKO11,GS14,BGM13} for
continuous opinions and \cite{FGV12,YOASS13,BFM16} for discrete ones).
A common assumption, that dates back to DeGroot \cite{DeGroot}, is
that opinions evolve through a form of repeated averaging of
information collected from the agent social neighborhoods.

Our work builds on the influential model of Friedkin and
Johnsen \cite{FJ90}. According to FJ-model, each agent $i$ holds an
internal opinion $s_i\in [0,1]$, which is private and
invariant over time and a public opinion $x_i \in [0,1]$
Initially, agents start with their internal opinion and at
each round $t\geq1$, update their public opinion
$x_i(t)$ to a weighted average of public opinion of
their social neighbors and their internal opinion, i.e.
\[
  x_i(t) =
  \frac{\sum_{j\neq i}w_{ij}x_j(t-1) + w_{ii}s_i}
  {\sum_{j\neq i}w_{ij}+w_{ii}}
\]
where the weights $w_{ij}$ indicate the influence between
the agents and $w_{ii}$ the self confidence towards their
internal belief.

The FJ-model is one of the most intensively studied models
in opinion dynamics. It admits a
unique equilibrium point $x^* \in [0,1]^n$ to which
the opinion vector $x(t)$ converges exponentially fast
\cite{GS14}.

Latter Bindel et al. introduced a game theoretic
view point in opinion formation processes \cite{BKO11}.
They considered the update rule of the FJ-model
as the minimizer of disagreement cost function
and based on this they defined an one shot
opinion formation game. The strategy of each agent $i$ is
her public opinion $x_i$, incuring her a
disagreement cost \[C_i(x_i,x_{-i})=\sum_{j \neq i}w_{ij}
(x_i-x_j)^2 + w_{ii}(x_i-s_i)^2\]
By definition the FJ-model is the
\emph{simultaneous best response dynamics} in the repeated
version of their one shot game and the Nash equilibrium
of their game concides with the equilibrium point
$x^*$ of the FJ-model. The reason for this definition
was to measure the inefficiency of the limiting behavior
of the FJ-model with respect to the total disagreement cost.
They proved that Price of Anarchy is less than $9/8$
in case $w_{ij}=w_{ji}$. Additionally, their work also introduced
an alternative framework for opinion dynamics.
Instead of defining update rules that model the
way opinions evolve, agents are considered to repeatedly
play a suitable one shot game. This consideration is
much more fruitful since it permits the agents to
update their opinions in more abstract ways.
For example it would be reasonable to consider
that in the above repeated game, agents instead of
adopting \emph{best response}, they update their opinions according
to a \emph{no-regret} learning algorithm.

\subsection{Motivation}
Our work is motivated by the fact that the FJ-model,
despite its simplicity making it a plausible choice
for modeling natural behavior, implies a large amount of
information exchage between the agents. At each round
its update rule requires that every agent learns all the
opinions of her social neighbors.
In todays's large social networks each user
may have several hundrends of friends and obviously
she cannot learn all these opinions each day.
This introduces some skeptism on how well the
FJ-model resembles the opinion formation in such
networks.

From a game-theoretic perspective FJ-model admits
very nice properties. It has a simple update rule, making it
a plausible choice for modeling natural behavior, that
is also the \emph{best response} of a well
defined opinion formation game. Moreover it ensures
convergence to the unique equilibrium $x^*$ of the opinion
formation game. However from a
distributed computing point of view, things are not
so great. The update rule of FJ-model requires that each agent learns
the opinion of all her social neighbors at each
round. In todays's large social networks each user
may have several hundrends of friends and obviously
she cannot learn the opinion of all them each day.
This introduce some skeptism on how well the
FJ-model resembles the opinion formation process in such
networks.

Our work is motivated by the following questions.
\begin{question}
Can we find variants of the FJ-model that
require less information exchange between the agents
and share similar convergence properties?
Can these models be justified as natural behavior for selfish
agents under a game-theoretic solution concept?
\end{question}

Generally speaking, it is not hard to
design distributed protocols that simulate FJ-model
and require each agent to learn \emph{just one} opinion
of her neighbors at each iteration. The problem is that these protocols
are way too \enquote{\emph{algorithmic}} and thus not suitable modeling
natural behavior. In order to formally establish what
the word \enquote{\emph{natural}} means, we introduce a randomized
variant of the one shot game defined in \cite{BKO11},
called \emph{opinion formation game with random payoffs}.
For an public opinion vector $x \in [0,1]^n$, the disagreement
cost $C_i(x_i,x_{-i})$ that each agent $i$ receives is
a random variable defined as follows:
\begin{itemize}
 \item agent $i$ meets \emph{one} of her neighbors $j$ with probability
 $p_{ij}=w_{ij}/(\sum_{j\neq i}w_{ij}+w_{ii})$
 \item and receives disagreement cost, $(1-\alpha_i)(x_i-x_j)^2 + \alpha_i(x_i-s_i)^2$
\end{itemize}
where $\alpha_i=w_{ii}/(\sum_{j\neq i}w_{ij}+w_{ii})$. The above game
has the same Nash equilibrium $x^*$ (w.r.t. the expected cost) as
the original opinion formation game and admits a nice interpretation
that we discuss latter.

Throughout the paper, we consider the agents to be engaged in the repeated
version of the above one shot game. The reason for this
consideration is twofold. The first is convience, the repeated
version of the above specifies the way that the agents communicate i.e.
at each round $t$ each agent $i$ learns just the opinion
of the agent that she randomly met. The second reason is that we can now define
what natural behavior is. Since at each round each agent
suffers a (random) disagreement cost that she selfishly want
to minimize, a natural update rule must provide garantees about
the cost that the agent experiences during the game play.
This work provides answers to the following questons:

\emph{How can the agents update their opinions in the above
repeated game such that:}
\begin{itemize}
\item \emph{Their experienced disagreement cost of each agent is in a sense minimized.}
\item \emph{The produced opinion vector $x(t)$ converges to equilibrium $x^*$
 relatively fast.}
\end{itemize}

\subsection{Contribution}
We introduce a simple and intuitive update rule,
similar to that of FJ-model, that the agents can adopt
and the resulting opinion vector $x(t)$ converges to $x^*$.
Our update rule is a \emph{Follow the Leader algorithm}
meaning that each round $t$, each agent updates her opinion
to the minimizer of total disagreement cost that
she experienced until round $t-1$. In section~\ref{s:fictitious_convergence},
we bound its convergence time and we show that in order
to acheive $\eps$ distance form $x^*$, poly($1/\eps$) rounds
are needed. In section~\ref{s:fictitious_noregret},
we show that the agents have \emph{no-regret} in adopting
it. Namely, the average disagreement cost (that
the agent experiences) per round approaches that
of expressing the best opinion in hindsight. The latter
makes our algorithm a natural choice for agents that
selfishly want to minize their incured disagreement cost.
Our results contribute to showing that the FJ-model
can be extended with simple variants to explain
the opinion formation process in enviroments with limited
information exchange.

In section~\ref{s:lower_bound}, we show
that for any update rule that ensures \emph{no-regret}
for the agents, the resulting opinion vector $x(t)$
cannot converge to $x^*$ faster than polynomially. We
prove the latter for a larger class of update rules,
\emph{opinion dependent update rules} using information
theoretic arguments. This implies that in our limited
information setting natural models cannot converge exponentially
fast. Finally in Section~\ref{s:cc_convergence}, we present
an update rule that is not opinion dependent and achieves exponential
convergence. Our results indicate the fundamental reason that
the FJ-model converges exponential fast, which has little
to do with the \enquote{large} information exchange that it requires.
They also serve as an \enquote{algorithmic guide} for future
variants of the FJ-model.

\subsection{Related Work}
Apart from the aforementioned results there exists a large amount
of literature concerning the FJ-model.
Many recent works \cite{BGM13,CKO13,BFM16,EFHS17} bound the
inefficiency of equilibrium in variants of opinion formation game
defined in \cite{BKO11}. In \cite{GS14} they bound that the convergence
time of the FJ-model in in special graph topologies.
In \cite{BFM16}, a variant of the opinion formation game in which social
relations depend on the expressed opinions, is studied.
They prove that, the discretized version of the above game admits
a potential function and thus best-response converges to the
Nash equilibrium. Convergence results in other discretized variants of
the FJ-model can be found in \cite{YOASS13,FGV16}. In \cite{FPS16} the convergence
properties of limited information variants of the Heglesmann-Krause model \cite{HK}
and the FJ model, are examined.


Other works, that relate to ours, concern the convergence
properties of dynamics based on no-regret learning algorithms.
In \cite{FV97,FS99,SA00,SALS15} it is proved that in a finite $n$-person
game if each agent updates her mixed strategy according to a no-regret
algorithm the resulting \emph{time-averaged} strategy vector converges to
Coarse Correlated Equilibrium. The convergence properties of no-regret dynamics
for games with infinite strategy spaces were considered in \cite{EMN09}.
They proved that for a large class of games with concave utility function
(socially concave games), the time-averaged strategy vector converges to
the PNE. More recent work investigate a stronger notion of convergence of
no-regret dynamics. In \cite{CHM17} they show that,
in $n$-person finite generic games that admit unique Nash equilibrium,
the strategy vector converges \emph{locally} and exponentially fast
to it. They also provide conditions for \emph{global} convergence.
Our results fit in this line of research since we show that
for a game with \emph{infinite} strategy space, the strategy vector
(and not the time-averaged) converges to the unique Nash equilibrium.

No-regret dynamics under limited information are also examined
in other settings. Kleinberg et al. in \cite{KPT09} treated
load-balancing in distributed systems as
a repeated game and analyzed the convergence properties
no-regret online algorithms under the \emph{full information assumption}
that each agent learns the load of every machine.
In a subsequent work \cite{KPT11}, the same authors consider the
same problem in a \emph{limited information setting} (\enquote{bulletin board model})
in which each agent learns the load of just the machine
that served him. In \cite{HCM17,MS17} they examine the convergence
properties of online learning algorithms in case the payoffs observed
by the agents are contaminated with some random noise.
