\section{Lower Bound for no-regret Dynamics}\label{s:lower_bound}

As we have already discussed for any fixed instance $I$ with
$\rho\geq 1/2$, \emph{fictitious play} achieves convergence rate
$\Expnew{I}{\norm{\infty}{x_A(t)-x^*}}=\bigOh{1/\sqrt{t}}$,
this rate is outperformed by the rate of the original \emph{FJ model}
convergence rate
$\Expnew{I}{\norm{\infty}{x(t)-x^*}}=\bigOh{1/2^{t}}$.
In this section we investigate whether there exists another no-regret
algorithm $A$ that the agents can select and ensures a better convergence rate
to the equilibrium.  We show the following

\begin{theorem}\label{t:dynamics_lower_bound}
  Let $A$ a no-regret algorithm and let $x_A(t)$ the
  opinion vector defined in \ref{alg:no_regret_dynamics}.
  For any $c>0$, there exists an instance $I_A$ such that
  $\Expnew{I_A}{\norm{\infty}{x_A(t)-x^*}} = \Omega(1/t^{1+c})$.
\end{theorem}
The above theorem states that rationality in selfish agents comes with
the price of slow convergence to the equilibrium point.

At first we show that any no-regret algorithm $A$, achieving the previous
convergence rate, can be used as an estimator of the parameter
$p \in [0,1] $ of Bernoulli random variable
with the same asymptotic error rate. The reduction is formally stated in
Lemma~\ref{l:reduction}.
Since we prove \ref{t:dynamics_lower_bound} using a reduction to
an estimation problem we shall first briefly introduce some definitions and
notation.
Given $t$ independent samples from a Bernoulli random variable $B(p)$
an estimator is an algorithm that takes these samples as inputs and
outputs an answer in $[0,1]$.
\begin{definition}\label{d:estimator}
  An estimator sequence $(\theta_t)_{t=1}^{\infty}$
  is a sequence of functions, $\theta_t: \{0,1\}^t\mapsto [0,1]$.
\end{definition}
Perhaps the first estimator that comes to one's mind is the
\emph{sample mean}, that is $\theta_t=(1/t) \sum_{i=1}^t X_i$.
Of course for an estimator to be efficient we would like its answer to be
close to the mean $p$ of the Bernoulli that generated the samples.
To measure the efficiency of an estimator we define the \emph{risk}
which corresponds to the expected loss of an estimator.
\begin{definition}\label{d:risk}
  For an estimator $\hat{\theta}
  =\{\hat{\theta_t}\}_{t=1}^\infty$ we define its convergence rate
  $R_p(\theta_t) = E_p[|\hat{\theta_t}(X_1,\ldots,X_t) - p|]$,
  where
  \[
    E_p[|\hat{\theta_t}(X_1,\ldots,X_t) - p|]
    = \sum_{(y_1,\ldots,y_t)\in\{0,1\}^t}
    |\hat{\theta_t}(y_1,\ldots,y_t) -p|\
    p^{\sum_{i=1}^t y_i}\ (1-p)^{t-\sum_{i=1}^t y_i}
  \]
\end{definition}
The quantity $E_p[|\hat{\theta_t}(Y_1,\ldots,Y_t) - p|]$ is the expected distance
of the estimated value $\hat{\theta_t}$ from the parameter $p$, when the
distribution of the samples is $B(p)$.
To simplify notation we will also denote it as $E_p[|\hat{\theta_t} - p|]$.
The error rate $R_p(\theta_t)$ quantifies the rate of
convergence of the estimated value $\hat{p} =\theta_t(Y_1,\ldots,Y_t)$ to the
real parameter $p$.  Since $p$ is unknown, any meaningful estimator $\hat{p}$
must guarantee that for all $p \in [0,1]$, $\lim_{t \to \infty}
R_p(t)=0$. For example, \emph{sample mean} has error rate $R_p(t) \leq
\frac{1}{2\sqrt{t}}$ for ant $p \in [0,1]$ and clearly satisfies the above
requirement.

We show now that any no-regret algorithm $A$, achieving the
convergence rate of Theorem~\ref{t:lower_bound}, can be used as an
estimator of the parameter $p \in [0,1]$ of a Bernoulli random variable with
the same asymptotic error rate.
The reduction formally stated and in Lemma~\ref{l:reduction}.
\begin{lemma}\label{l:reduction}
  Let $A$ be a no-regret algorithm $A$ such that for all instances $I$,
  $\lim \limits_{t \rightarrow \infty} t^{1+c}
  \Expnew{I}{\norm{\infty}{x_A(t)-x^*}}=0$.
  Then there exists an estimator $\hat{\theta_A}$ such that
  for all $p \in [0,1]$,
  \[\lim_{t \rightarrow \infty}t^{1+c}R_p(\theta_t)=0\]
\end{lemma}


We sketch here the main idea. For a full proof see Section~\ref{app:s:lower_bound}
of the Appendix.  For a given $p \in [0,1]$, we construct an instance $I_p$ such that
$x_c^*=p$ for an agent $c$. Moreover, agent $c$ must
receive only values $1$ or $0$ with probability $p$ and $1-p$ respectively.
This can be easily done using the star graph $K_{1,2}$.
The agent corresponding to the center node, $c$, has $\alpha_c = 1/2$ and
whereas the leaf nodes have $a_{1,2} = 1$, $s_1 = 0$, $s_2 = 1$,
as shown in Figure~\ref{fig:lb_instance}.
%
\begin{figure}\
  \centering

  \begin{tikzpicture}
    \begin{scope}[every node/.style={circle,draw}]
      % \node (C) at (0,0) [label=below:$a_c \equal 0$][label=above:$s_c \equal 0$]{C};
      % \node (1) at (-4,0)[label=below:$a_1 \equal 1$][label=above:$s_1 \equal 0$]{1};
      % \node (2) at (4,0) [label=below:$a_2 \equal 1$][label=above:$s_2 \equal 1$]{2};
      \node (C) at (0,0) [label=below:$a_c \equal 0\comma s_c \equal 0$]{C};
      \node (1) at (-4,0)[label=below:$a_1 \equal 1\comma s_1 \equal 0$]{1};
      \node (2) at (4,0) [label=below:$a_2 \equal 1\comma s_2 \equal 1$]{2};
    \end{scope}

    \begin{scope}[>={Stealth[black]},
      every node/.style={fill=white,circle},
      every edge/.style={draw=black}]
      \path [-] (C) edge node {$p$} (1);
      \path [-] (C) edge node {$1-p$} (2);
    \end{scope}
  \end{tikzpicture}
  \caption{The Lower Bound Instance} \label{fig:lb_instance}
\end{figure}
%
It follows that the estimator $\theta_t$ with $\theta_A^t = x_A^c(t)$
has error $R_p(\theta_t)=\Expnew{I_p}{\norm{\infty}{x_A(t)-x^*}}$.
Meaning that if $A$ does not satisfy Theorem~\ref{t:dynamics_lower_bound}
then $\lim\limits_{t \rightarrow \infty}t^{1+c}R_p(\theta_t)=0$ for all
$p \in [0,1]$. Thus we want to prove the following claim
\begin{claim}\label{cl:fixed_p}
  For all sequences of estimators $\theta_t$
  Then, there exists a fixed $p \in [0,1]$ such that
  \[
    \lim_{t \to \infty} t^{1+c} \Expnew{p}{|\theta_t - p} > 0.
  \]
\end{claim}
The crucial point of Claim~\ref{cl:fixed_p} is the fact that
in order to construct the hard instance for the estimator
we first inspect the sequence of estimators and then choose
a $p \in [0,1]$ so that \emph{all} estimators $\theta_t$ of
the sequence have error rate $\omega(1/t^{1+c})$.

At this point we should mention that it is known
that $\Omega(1/\eps^2)$ samples are needed to estimate the parameter $p$
of a Bernoulli random variable within additive error $\eps$.
Another well-known result is that taking the average of the samples
is the \emph{best} way to estimate the mean of a Bernoulli random variable.
These results would indicate that the best possible rate of convergence
for a no-regret dynamics would be $O(1/\sqrt{t})$.
However, there is some fine print in these results which does not allow us
to use them. In order to explain the various limitations of
these methods and results we will briefly discuss some of them.

Perhaps the oldest sample complexity lower bound for estimation problems
is the well-known Cramer-Rao inequality.
Assuming that $\theta_t$ is a sequence of unbiased estimators,
that is $\Exp{\theta_t} = p$ for all $t$, the Cramer-Rao lower bound
for estimating the mean $p$ of a Bernoulli random variable states
that
\begin{equation}\label{eq:crlb}
  \Expnew{p}{(\theta_t - p)^2} \geq \frac{p(1-p)}{t}.
\end{equation}
In our setting, we can lower bound $\Expnew{p}{|\theta_t - p|}$ by
$\Expnew{p}{(\theta_t - p)^2}$ since $|\theta_t - p| \leq 1$
(making the natural assumption that estimators do not output values outside
$[0,1]$).
Simply setting $p=1/2$ in inequality (\ref{eq:crlb}) would give us a
$p$ satisfying the requirements of Claim~\ref{cl:fixed_p}.
The problem with this lower bound is that the assumption that the estimator
is unbiased is considered rather restrictive and unrealistic even in
the statistics literature in the sense that many efficient practical
estimators are not unbiased.  Thus, we would like to get a lower bound
with minimal assumptions about the estimator.

To the best of our knowledge, sample complexity lower bounds without
assumptions about the estimator are given as lower bounds for the
\emph{minimax risk}, which was defined
\footnote{
Although the minimax risk is defined for any estimation problem and loss
function, for simplicity, we write the minimax risk for estimating the mean
of a Bernoulli random variable.}
  by Wald in \cite{Wal39} as
\[
  \inf_{\theta_t} \sup_{p\in[0,1]} \Expnew{p}{|\theta_t - p|}.
\]
Minimax risk captures the idea that after we pick the best possible
algorithm, an adversary inspects it and picks the worst possible
$p \in[0,1]$ to generate the samples that our algorithm will get as input.
The methods of Le'Cam, Fano, and Assouad are well-known
information-theoretic methods to establish lower bounds for the minimax risk.
For more on these methods see \cite{Yu97, Tsy08} and the
very good lecture notes of Duchi, \cite{duchi_stats311}.
As we stated before, it is well known that the minimax risk for the
case of estimating the mean of a Bernoulli is lower bounded by
$\Omega(1/\sqrt{t})$ and this lower bound can be established
by Le Cam's method.
In order to show why such arguments do no work for our purposes
we shall sketch how one would apply Le Cam's method to get this lower bound.
To apply Le Cam's method, one typically chooses two Bernoulli distributions
whose means are far but their total variation distance is small.
Le Cam showed that when two distributions are close in total variation then
given a sequence of samples $X_1, \ldots, X_t$ it is hard to tell whether
these samples were produced by $P_1$ or $P_2$. The hardness of this \emph{testing}
problem implies the hardness of \emph{estimating} the parameters of
a family of distribution.
For our problem the two distributions would be $B(1/2 - 1/\sqrt{t})$
and $B(1/2 + 1/\sqrt{t})$. It is not hard to see that their total variation
distance is at most $O(1/t)$, which implies a lower bound
$\Omega(1/\sqrt{t})$ for the minimax risk. The problem here is that
the parameters of the two distributions depend on the number of
samples $t$. The more samples the algorithm gets to see, the closer
the adversary takes the $2$ distributions to be.
For our problem we would like to \emph{fix} an instance and then argue
about the rate of convergence of any algorithm on this instance.
Namely, having an instance that depends on $t$ does not work for us.

Trying to get a lower bound without assumptions about the estimators
while respecting our need for a fixed (independent of $t$) $p$ we prove
Lemma~\ref{l:estimation_lower_bound}.
In fact, we show something stronger:
for \emph{almost all} $p \in [0,1]$, any estimator $\hat{\theta}$ cannot
achieve rate $o(1/t^{1+c})$.
More precisely,  suppose we select a $p$ uniformly at
random in $[0,1]$ and run the estimator $\hat{\theta}$ with samples from the
distribution $B(p)$, then with probability $1$ the error rate $R_p(\theta_t) \in
\Omega(1/t^{1+c})$. Although we do not show the sharp lower bound
$\Omega(1/\sqrt{t})$ we prove that no exponential convergence rate
is possible.
Finally, while we do not preclude the possibility of similar results to exist
in the statistics literature, we remark that our proof is fairly simple,
intuitive, and could be of independent interest.


\begin{lemma}\label{l:estimation_lower_bound}

  Let $\hat{\theta}$ an estimator for the parameter $p$ of a Bernoulli
  random variable with error rate $R_p(\theta_t)$.
  If we select $p$ uniformly at random in $[0,1]$ then
  \[
    \Prob{\lim_{t\to \infty} t^{1+c} R_p(\theta_t)\ > 0}=1,
  \]
  for any $c>0$.

\end{lemma}
\begin{proof}

  Let an estimator $\hat{\theta} = \{\theta_t\}_{t=1}^{\infty}$, where
  $\theta_t: \{0,1\}^t\mapsto [0,1]$.  The function $\theta_t$ can have at most
  $2^t$ different values. Without loss of generality we assume that
  $\theta_t$ takes the same value $\theta_t(x)$ for all $x \in \{0,1\}^t$
  with the same number of $1$'s. For example,
  $\theta_3(\{1,0,0\})=\theta_3(\{0,1,0\})=\theta_3(\{0,0,1\})$.
  This is due to the fact that for any $p \in[0,1]$,
  %
  \[
    \sum_{0 \leq i \leq t} \sum_{\norm{1}{x} = i} \lp| \theta_t(x) - p \rp|
    p^i (1-p)^{t-i} \geq \sum_{0 \leq i \leq t} \binom{t}{i} \lp|
    \frac{\sum_{\norm{1}{x} = i} \theta_t(x)}{\binom{t}{i}}  - p \rp| p^i
    (1-p)^{t-i}.
  \]
  %
  For any estimator with error $R_p(\theta_t)$ there exists another estimator
  with $R'_p(t)$ that satisfies the above property and
  $R_p'(t) \leq R_p(\theta_t)$.
  Thus we can assume that $\theta_t$ takes at most $t+1$ different
  values.
  %
  Let $A$ denote the set of $p$ for which the estimator has error
  rate $o(1/t^{1+c})$, that is
  %
  \[
    A= \{p\in [0,1]: \lim_{t \to \infty} t^{1+c}R_p(\theta_t)=0\}
  \]
  We show that if we select $p$ uniformly at random in $[0,1]$ then
  $\Prob{p \in A} = 0$.  We also define the set
  \[
    A_k=\{p\in [0,1]: \text{for all }t \geq k,~ t^{1+c}R_p(\theta_t)\leq 1/2\}
  \]
  %
  Observe that if $p \in A$ then there exists $t_p$ such that
  $p \in A_{t_p}$, meaning that
  $A \subseteq \cap_{k=1}^{\infty}A_k$.  As a result,
  \[
    \Prob{p \in A} \leq \Prob {p \in\bigcup_{k=1}^{\infty}A_k} \leq
    \sum_{k=1}^{\infty}\Prob{p \in A_k}
  \]
  %
  To complete the proof we show that $\Prob{p \in A_k}=0$ for all $k$.
  Notice that $p \in A_k$ implies that for $t \geq k$, the estimator
  $\hat{\theta}$ must always have a value $\theta_t(i)$ close to $p$.
  Using this intuition we define the set
  \[
    B_k = \{p \in [0,1]: \text{for all
    }t\geq k,~ t^{1+c}\min_{0\leq i \leq t}|\theta_t(i)-p| < 1\}
  \]

  We now show that $A_k \subseteq B_k$.
  Since $p \in A_k$ we have that for all $t\geq k$
  \[
    t^{1 + c} \min_{0 \leq i \leq t} \lp| \theta_t(i) - p \rp|
    \sum_{i=0}^t \binom{t}{i} p^i (1-p)^{t-i}
    \leq
    t^{1 + c} \sum_{i=0}^t \binom{t}{i} \lp| \theta_t(i) - p \rp| p^i (1-p)^{t-i}
    = t^{1+c} R_p(\theta_t)
    \leq
    1/2.
  \]
  Thus, $\Prob{p \in A_k} \leq \Prob{p \in B_k}$.
  At first we write the set $B_k$ in the following equivalent form
  $
  B_k = \cap_{t=k}^{\infty}\{p \in [0,1]:~ \min_{0 \leq
    i \leq t} |\theta_t(i)-p|\leq 1/t^{1+c}
  \}$.
  As a result,
  \[
    \Prob{p \in B_k}
    \leq \Prob{\min_{0 \leq i \leq t}|\theta_t(i)-p| \leq 1/t^{1+c} },
    \text{for all } t \geq k
  \]
  \begin{figure}
  \centering
  \begin{tikzpicture}[scale=7]
  \draw[-, thick] (0,0) -- (1,0);
  \foreach \x/\xtext in {0/0,0.2/$\theta_t(0)$,0.4/$\theta_t(1)$,0.8/$\theta_t(t)$,1}
      \draw[thick] (\x,0.5pt) -- (\x,-0.5pt) node[below] {\xtext};
  %\draw (0.2,0.5pt) node[above] {$c$};
  \draw[(-), thick, black] (0.12,0) -- (0.28,0);
  \draw[(-), thick, black] (0.32,0) -- (0.48,0);
  \draw (0.6,-1.2pt) node[below] {. . . };
  \draw[(-), thick, black] (0.72,0) -- (0.88,0);
  \draw[|-|] (0.12,1pt) -- (0.28,1pt) node[midway, above] {$\frac{2}{t^{1+c}}$};
  \draw[|-|] (0.32,1pt) -- (0.48,1pt) node[midway, above] {$\frac{2}{t^{1+c}}$};
  \draw[|-|] (0.72,1pt) -- (0.88,1pt) node[midway, above] {$\frac{2}{t^{1+c}}$};
  %\draw (-0.25,0) node {At time $t$};
  \end{tikzpicture}
  \caption{Estimator output at time $t$} \label{fig:estimator}
\end{figure}
  Each value $\theta_t(i)$ \enquote{covers} length $1/t^{1+c}$ from
  its left and right, as shown in Figure~\ref{fig:estimator}
  , and since there are at most $t+1$ such values
  we have for all $t \geq k$ the set
  \[
    \{
    p \in [0,1]\ :\ {\min_{0 \leq i \leq t} |\theta_t(i)-p| \leq 1/t^{1+c} }
    \}
    =
    \bigcup_{i=0}^t
    \lp(
    \theta_t(i) - \frac{1}{t^{1+c}},\ \theta_t(i) + \frac{1}{t^{1+c}}
    \rp).
  \]

  For each interval in the above union we have that
  $\Prob{|\theta_t(i)-p| \leq 1/t^{1+c}}\leq 2/t^{1+c}$
  and by the union bound we get
  $\Prob{p \in B_k} \leq 2(t+1)/t^{1+c}$, for all $t \geq k$.
  We conclude that $\Prob{p \in B_k} =0$.
\end{proof}
