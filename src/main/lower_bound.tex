\section{Final Lower Bound}
As we have already discussed in \ref{d:regret} a no-regret algorithm $A$ defines no-regret dynamics for any fixed instance $I=(G,s,a)$. 
Let $\Expnew{I}{\norm{\infty}{x(t)-x^*}}$ denote the convergence rate of the above dynamics. Since $A$ ensures no-regret for each agent $i$, this 
dynamical process can be considered as a natural dynamical process. In this section we investigate whether there exists such a no-regret algorithm that
guarantees significantly better asymptotic convergence rate than those that \emph{fictitious play} provides. In this section we present some results that 
indicate that the following question admits an negative answer.
\begin{question}
Is there a no-regret algorithm $A$ such that for all instance $I=(G,s,a)$, $\Expnew{I}{\norm{\infty}{x(t)-x^*}} \in \bigOh{1/t}$? 
\end{question}

\noindent Altough we were not able to answer provide a negative answer to the above question, we present to main results that indicate that the existence of such
an algorithm is higly unlikely. More precisely, we were able to prove two following theorems.

\begin{theorem}
Let a no-regret alogrithm $A$ such that for all instances $I$, $\lim_{t \rightarrow \infty} t\Expnew{I}{\norm{\infty}{x(t)-x^*}}=0$.\\
Then there exists an estimator $\hat{\theta}$ such that $\text{for all }p \in Q[0,1],~  \lim_{t \rightarrow \infty}tR_p(t)=0$
\end{theorem}

\begin{theorem}
Let a Bernoulli estimator $\hat{\theta}$ with error rate $R_p(t)$. Then, for all $[a,b] \subseteq [0,1]$,
\[ \lim_{t \to \infty}t \int_{a}^{b}R_p(t)dp = +\infty\]
\end{theorem} 

\noindent As result the existence of such an algorithm $A$ implies the existence of estimator $\hat{\theta}$ with error rate $R_p(t)$ that satisfies the following
two properties:
\begin{itemize}
 \item for all $p \in Q([0,1]),~ \lim_{t \rightarrow \infty}tR_p(t)=0$
 \item for all $[a,b] \subseteq [0,1]$, $\lim_{t \to \infty}t \int_{a}^{b}R_p(t)dp = +\infty$
\end{itemize}
\noindent We conjecture that the does not exist such a function $R_p(t)$. Even if it is not the case, such a fuction admits an very degenerate form making very likely to be
the error rate of any reasonable estimator $\hat{\theta}$. 


\subsection{Proof of Theorem 4}
\begin{lemma}
For any graph oblivious update rule $F=\{\ f \}_{t=1}^\infty$, there exists a Bernulli estimator $\hat{\theta_F}$ such that\\
for all $q \in Q([0,1])$, there exists an instance $I_q$ such that $$E_q[|\hat{\theta_t} - q|] \leq 2E_{I_q}[||x^t-x^*||_{\infty}]$$
\end{lemma}

\begin{proof}
At round $t$, the graph oblivious update rule $F=\{\ f_t\}_{t=1}^\infty$ has selected the functions $f_t(O_1,\ldots,O_t,s_i,a_i)$ and $g_t(s_i,a_i)$. An estimator $\hat{\theta}$ receives the samples $Y_1,\ldots,Y_t$ and outputs the value $\hat{\theta_t}(Y_1,\ldots,Y_t) \in [0,1]$. Now consider the estimator $\hat{\theta_t}=\frac{1}{2}f(g_1(Y_1,1),\ldots,g_t(Y_t,1))$ and observe that $\hat{\theta_t}$ is a function $\{0,1\}^t \mapsto [0,1]$.\\
Now for any $q \in Q([0,1])$, construct an appropriate instance $I_q$ such that $E_q[|\hat{\theta_t} - q|] \leq 2E_{I_q}[||x^t-x^*||_{\infty}]$.\\
Since $q=\frac{k}{n}$ some $k,n \in \nats$, the following instance $I_q$ with $n+1$ agents:
\begin{itemize}
 \item A central agent with $s_c=0$ and $a_c=1/2$.
 \item Directed edges from the central agent to all the other agents.
 \item $k$ agents with $s_i=0$ and $a_i=1$
 \item $n-k$ agents with $s_i=1$ and $a_i=1$
 \end{itemize}
Notice that in this instance for all $i\neq c$, $x^*_i=s_i$ and $x^*_c=\frac{q}{2}$. We show that $E_q[|\hat{\theta_t}-q|] \leq 2E_{I_q}[||x^t-x^*||_{\infty}]$.\\
At round $t$, if the oracle returns to the center agent the value $g_t(1,1)$ of a $1$-agent, then $Y_t=1$ otherwise $Y_t=0$. As a result, $\Prob{Y_t=1}=q$ and 
\begin{align*}
 E_{I_q}[||x^t-x^*||_{\infty}] &\geq E_{I_q}[|x^t_c-x^*_c|]\\
 &= E_{q}[|\frac{\hat{\theta_t}}{2}-\frac{q}{2}|]
\end{align*}
\end{proof}

\begin{corollary}
Let the update rule $F=\{f_t\}_{t=1}^\infty$ s.t. for all instances $I$, $\lim_{t \rightarrow \infty} t E_I[||x^t -x^*||]=0$.
Then for any  $q \in Q[0,1]$, $$\lim_{t \rightarrow \infty}tE_q[|\hat{\theta_F} -q|]=0$$
\end{corollary}

\subsection{Proof of Theorem 5}
\section{Lower Bound}


\begin{lemma}[Fano's Inequality]\label{l:fano}
Suppose we have an estimator $\hat{\theta}^t$ for the probability of a Bernoulli distribution. 
The unknown distribution belongs to a family of distributions $\mathcal{P}$ with the property that the probabilities of every two distributions in this family differ by at least $2\delta$, where $\delta$ is a positive real number.
Then, for every subset ${P_1, P_2, ..., P_n}$ of distributions from this family, where $p_i$ is the probability of distribution $P_1$, the following inequality holds:
$$\frac{1}{n} \sum_{i=1}^n \Exp{\lp|\hat{\theta}^t-p_i\rp|} \geq \delta \lp(1-\frac{I(X;V)+\log 2}{\log n}\rp)$$
\end{lemma}

We are now going to use Theroem~(\ref{l:fano}) to prove the following lemma, which provides a lower bound for the mean of the expectation of errors of the estimator.
\begin{lemma}\label{l:fano_application}
Suppose we choose $t$ Bernoulli distributions $\{P_i\}_{i=0}^{t-1}$ with the following probabilities: $$p_i = a+\frac{b-a}{2t} + i \frac{b-a}{t} , i=0, ..., t-1$$. Then:
$$\frac{1}{t} \sum_{i=1}^t \Exp{\lp|\hat{\theta}^t-p_i\rp|} \geq \frac{b-a}{2t} \lp(c_1 - \frac{c_2}{t}\rp)$$
where $c_1, c_2 >0$ and $c_1 > \frac{1}{2}$.
\end{lemma}

Next, we state a lemma regarding an upper bound on the expectation of the error in each $p_i$.
\begin{lemma}\label{l:cauchy_schwarz}
For every $p\in [-(b-a)/{2t} + p_i , p_i + (b-a)/{2t}]$ :
$$\Exp{\lp|\hat{\theta}^t-p_i\rp|}_{p_i} \leq c_a^b\Exp{\lp|\hat{\theta}^t-p\rp|}_p + \lp|p - p_i\rp|
$$
where $c_a^b$ is a constant that depends on $a,b$.
 
\end{lemma}
Now, we find an upper bound for the quantity $\sum_{i=0}^{t-1} E_i$.
Our goal is to find an upper bound where the coefficient of $(b-a)/t$ is less than $1/4$.

\begin{lemma}\label{l:upper}
\[ \frac{1}{t} \sum_{i=0}^{t-1} E_i \leq \frac{c_a^b}{b-a} \int_a^b \Exp{\lp|\hat{\theta}^t-p\rp|} dp + \frac{b-a}{4t}\]

\end{lemma}

\begin{theorem}\label{t:lower_bound}
Suppose $\hat{\theta}^t$ is an estimator for the probability $p$ of a Bernoulli random variable that takes $t$ samples. Then, for every interval $[a,b]$ which is contained in $[0,1]$ and for every $c>0$, it holds that:
$$ \lim_{t\to\infty} t^{1+c}\int_{a}^b \Exp{\norm{\infty}{\hat{\theta}^t-p}}dp = \infty$$
\end{theorem}
\begin{proof}
By combining Lemmas~(\ref{l:fano_application}) and ~(\ref{l:upper}) we get:
\[\frac{c_a^b}{b-a} \int_a^b \Exp{\lp|\hat{\theta}^t-p\rp|}_p dp \geq \frac{b-a}{2t}\lp(\lp(c_1 - \frac{1}{2}\rp)- \frac{c_2}{t}\rp)\]
By multiplying by $t^{1+c}$ we get:
\begin{equation}\label{eq:final}
\frac{c_a^b}{b-a}t^{1+c} \int_a^b \Exp{\lp|\hat{\theta}^t-p\rp|}_p dp \geq \frac{b-a}{2}t^c\lp(\lp(c_1 - \frac{1}{2}\rp)- \frac{c_2}{t}\rp)
\end{equation}
The coefficient of $t^c$ in the right hand side of~(\ref{eq:final}) is positive, so by sendig $t \to \infty$ we get:
\[ \lim_{t\to\infty} t^{1+c}\int_{a}^b \Exp{\norm{\infty}{\hat{\theta}^t-p}}dp = +\infty\]
\end{proof}
