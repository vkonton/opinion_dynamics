\section{Lower Bound}
\begin{lemma}
  Let $P=B(p)$ and $Q=B(q)$ be two Bernoulli distributions then
  \[
    \dkl{P}{Q} \leq
    \lp(\frac{1}{p (1-p)} + \frac{1}{q (1-q)} \rp) \frac{(p - q)^2}{2}
  \]

\end{lemma}
\begin{proof}
  We have that
  \(
    \dkl{P}{Q} = p \log (p/q) + (1-p) \log((1-p)/(1-q))
  \).
  Let
  \[
    f(x,y) =
    x \log\left(\frac{x}{y}\right) +
    (1-x) \log\left(\frac{1-x}{1-y}\right)
  \]
  To simplify notation fix $y$ and  let $g(x) = f(x,y)$.  We have
  \begin{align*}
    g'(x) = - \log\lp(\frac{1-x}{1-y}\rp) + \log\lp(\frac{x}{y}\rp),
    \qquad g''(x) = \frac{1}{(1-x)x}
  \end{align*}
  If $x < y$ using Taylor in the interval $[x,y]$ we have for a $\xi \in [x,y]$
  \[
    g(x) = g(y) + g'(y)(y-x) + g''(\xi) (y-x)^2/2 = g''(\xi) (x-y)^2/2.
  \]
  If $x> y$ the using Taylor in the interval $[y,x]$ we get the same
  expression as above.
  Since $g''(x)$ is convex and is minimized at $x_0 = 1/2$ we have that
  if $|x-1/2| < |y-1/2|$ then $g''(\xi) \leq g''(y)$
  else $g''(\xi) \leq g''(x)$.  Therefore,
  \[
    g(x) =
    f(x,y) \leq
    \max(g''(x), g''(y))(x-y)^2/2 \leq  (g''(x) + g''(y)) (x-y)^2/2
  \]
\end{proof}

We are now going to use Lemma~(\ref{l:fano}) to prove the following lemma,
which provides a lower bound for the mean of the expectation of errors
of the estimator.
\begin{lemma}\label{l:fano_application}
  Suppose we choose $t$ Bernoulli distributions $\{P_i\}_{i=0}^{t-1}$
  with the following probabilities:
  \[
    p_i = a+\frac{b-a}{2t} + i \frac{b-a}{t} , i=0, ..., t-1
  \].
  Then:
  $$
  \frac{1}{t} \sum_{i=1}^t \Exp{\lp|\hat{\theta}_t-p_i\rp|}
  \geq \frac{b-a}{2t} \lp(c_1 - \frac{c_2}{t}\rp)
  $$
  where $c_1, c_2 >0$ and $c_1 > \frac{1}{2}$.
\end{lemma}
\begin{proof}
  Without loss of generality, we can assume that $t$ is a multiple of 5.
  For simplicity, we set $E_i = \Exp{\lp|\hat{\theta}_t-p_i\rp|}$.
  By the choice of $p_i$, we have that $$\lp|p_i - p_j\rp| \geq \frac{b-a}{t}$$,
  for every distinct $i,j$ in the family.
  This means that for the family of $t$ distributions that we picked, the property
  of Lemma~(\ref{l:fano}) is satisfied for $\delta = \frac{b-a}{2t}$.
  Thus, by dividing the $t$ distributions into groups of 5 and applying
  Lemma~(\ref{l:fano}) to each one, we obtain:
  \begin{align}\label{eq:fano}
    \frac{\sum{k =i}^{i+4}}{5}
    &\geq
    \frac{b-a}{2t}\lp(1-\frac{I(X;V)+\log 2}{\log n}\rp) \nonumber\\
    &=
    \frac{b-a}{2t}\lp(1- \frac{\log 2}{\log 5} - \frac{I(X;V)}{\log5}\rp) \nonumber\\
    &=
    \frac{b-a}{2t}\lp(c_1 - \frac{I(X;V)}{\log5}\rp)
  \end{align}
  where $c_1 = 1-\frac{\log2}{\log5} > \frac{1}{2}$.
  We are now going to upper bound the mutual information $I(X;V)$ for every
  group of 5 distributions. We denote by $P_i^t$ the distribution on
  vectors with $t$ coordinates,
  where each coordinate is sampled independently from $P_i$.
  Let $U= \{i,i+1,i+2,i+3,i+4\}$ be a family of 5 distributions.
  Using a well known inequality REFERENCE NEEDED HERE:
  \begin{align*}
    I(X;V)
    &\leq
    \frac{1}{5^2}\sum_{\substack{i,j \in U \\i\neq j}} D_{kl}\lp(P_i^t,P_j^t\rp)\\
    &\leq
    D_{kl}\lp(P_i^t, P_{i+4}^t\rp)\\
    &=
    t D_{kl}\lp(P_i, P_{i+4}\rp)\\
    &\leq
    t \frac{\lp(p_i - p_{i+4}\rp)^2}{p_i(1-p_i)}\\
    &\leq
    t\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp) \lp(p_i - p_{i+4}\rp)^2\\
    &=
    t\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp)\lp(\frac{b-a}{2t} +
    i\frac{b-a}{t} - \frac{b-a}{t} -(i+4)\frac{b-a}{t}\rp)^2\\
    &=
    t\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp) \frac{16(b-a)^2}{t^2}\\
    &=
    \frac{16(b-a)^2}{t} \lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp)
  \end{align*}
  So, if we set
  $$c_2 = 16\frac{(b-a)^2}{\log5}\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp)$$
  then by equation~(\ref{eq:fano}) we obtain:
  \begin{equation}\label{eq:fano5}
    \sum_{k =i}^{i+4} \geq \frac{5(b-a)}{2t}\lp(c_1 - \frac{c_2}{t}\rp)
  \end{equation}
  Inequality~(\ref{eq:fano5}) holds for every group of 5
  distributions. By summing up for all groups:
  \begin{align*}
    \sum_{i=0}^{t-1} E_i &\geq t \frac{b-a}{2t}\lp(c_1 - \frac{c_2}{t}\rp)\\
    &= \frac{b-a}{2}\lp(c_1 - \frac{c_2}{t}\rp)
  \end{align*}
  which is what we wanted to prove.
\end{proof}

Next, we state a lemma regarding an upper bound on the
expectation of the error in each $p_i$.
% \begin{lemma}\label{l:cauchy_schwarz}
%   For every $p\in [-(b-a)/{2t} + p_i , p_i + (b-a)/{2t}]$ :
%   \[
%     \Exp{\lp|\hat{\theta}_t-p_i\rp|}_{p_i}
%     \leq c_a^b\Exp{\lp|\hat{\theta}_t-p\rp|}_p + \lp|p - p_i\rp|
%   \]
%   where $c_a^b$ is a constant that depends on $a,b$.

% \end{lemma}
\begin{lemma}\label{l:cauchy_schwarz}
  Let $p, q \in [0,1]$ and Let $P = B(p)$, $Q = B(q)$ be two Bernoulli
  distributions with corresponding product distributions $P^t, Q^t$.
  Moreover, let $\hat{\theta}_t: \{0,1\}^t \to [0,1]$ be an estimator.
  Then
  \[
    \lp|
    \Expnew{P^t}{|\hat{\theta}_t-p |}
    - \Expnew{Q^t}{|\hat{\theta}_t-q |}
    \rp|
    \leq
    \sqrt{\Expnew{P^t}{(\hat{\theta}_t-p)^2}}
    \sqrt{ \lp( \frac{q^2}{p} + \frac{(1-q)^2}{1-p} \rp)^t - 1}
    + |p - q|,
  \]
\end{lemma}
\begin{proof}
  By the triangle inequality we have
  \begin{equation}\label{eq:triangle_inequality}
    \lp|
    \Expnew{P^t}{|\hat{\theta}_t-p |} -
    \Expnew{Q^t}{|\hat{\theta}_t-q |}
    \rp|
    \leq
    \lp|
    \Expnew{P^t}{|\hat{\theta}_t-p |} -
    \Expnew{Q^t}{|\hat{\theta}_t-p |}
    \rp|
    + |p - q|
  \end{equation}
  To simplify notation let $X = (X_1, \ldots, X_t)$ be the sample and let
  $r(X) = | \hat{\theta}_t(X)  - p |$. Moreover, denote
  by $p(x)$ resp. $q(x)$ the density functions of $B(p)$ resp. $B(q)$.
  $p_t: \{0,1\}^t \to [0,1]$ resp. $q_t$ be the density functions of
  the product distribution $P^t$, i.e.
  namely $p_t(x) = \prod_{i=1}^t p(x_i)$.
  We have
  \begin{align*}
    \Expnew{P_t}{r(X)} - \Expnew{Q^t}{r(X)}
    &=
    \sum_{x \in \{0,1\}^t} r(x) p_t(x) -
    \sum_{x \in \{0,1\}^t} r(x) q_t(x)
    \\
    &=
    \sum_{x \in \{0,1\}^t} r(x) (p_t(x) - q_t(x))  \\
    &=
    \sum_{x \in \{0,1\}^t} r(x) \sqrt{p_t(x)}\
    \frac{p_t(x) - q_t(x)}{\sqrt{p_t(x)}}
  \end{align*}
  From Cauchy-Schwarz inequality we have
  \begin{align}\label{eq:cauchy_schwarz}
    \lp(\Expnew{P^t}{r(X)} - \Expnew{Q^t}{r(X)}\rp)^2
    &\leq
    \lp(
    \sum_{x \in \{0,1\}^t} r^2(x) p_t(x)
    \rp)
    \lp(
    \sum_{x \in \{0,1\}^t} \frac{(p_t(x) - q_t(x))^2}{p_t(x)}
    \rp)
  \end{align}
  Notice that
  \begin{align*}
    \sum_{x \in \{0,1\}^t} \frac{(p_t(x) - q_t(x))^2}{p_t(x)}
    &=
    \sum_{x \in \{0,1\}^t} p_t(x) - 2 q_t(x) + \frac{q_t^2(x)}{p_t(x)}\\
    &=
    -1 + \sum_{x \in \{0,1\}^t} \frac{q_t^2(x)}{p_t^2(x)} p_t(x)\\
    &=
    -1 + \Expnew{P^t}{\frac{q_t^2(X)}{p_t^2(X)}}
  \end{align*}
  Since $X_i$ are independent we have
  \begin{equation}\label{eq:bernoulli_square_diff}
    \Expnew{P^t}{\prod_{i=1}^t\frac{ q^2(X_i)}{p^2(X_i)}}
    =
    \lp(\Expnew{P}{\frac{ q^2(X_1)}{p^2(X_1)}}\rp)^t
    = \lp( \frac{q^2}{p} + \frac{(1-q)^2}{1-p} \rp)^t
  \end{equation}
  Combining equations
  (\ref{eq:triangle_inequality}),
  (\ref{eq:cauchy_schwarz}),
  (\ref{eq:bernoulli_square_diff}) yields the result.
\end{proof}

Now, we find an upper bound for the quantity
$\sum_{i=0}^{t-1} E_i$.
Our goal is to find an upper bound where the coefficient of
$(b-a)/t$ is less than $1/4$.

\begin{lemma}\label{l:upper}
  \[
    \frac{1}{t} \sum_{i=0}^{t-1}
    E_i \leq
    \frac{c_a^b}{b-a} \int_a^b \Exp{\lp|\hat{\theta}_t-p\rp|} dp +
    \frac{b-a}{4t}
  \]
\end{lemma}
\begin{proof}
  By Lemma~(\ref{l:cauchy_schwarz}) we get that
  for every $p\in [-(b-a)/{2t} + p_i , p_i + (b-a)/{2t}]$:
  $$E_i \leq  c_a^b\Exp{\lp|\hat{\theta}_t-p\rp|}_p + \lp|p_i - p\rp|$$
  We integrate both sides of the equation with respect to p and get:
  \[
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}} E_i dp \leq c_a^b
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}
    \Exp{\lp|\hat{\theta}_t-p\rp|}_p dp +
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}\lp|p_i - p\rp| dp
  \]
  Hence:
  \begin{align*}
    \frac{b-a}{t} E_i
    &\leq
    c_a^b\int_{p_i - \frac{b-a}{2t}}^{p_i+ \frac{b-a}{2t}}
    \Exp{\lp|\hat{\theta}_t-p\rp|}_p dp +
    2\int_{p_i - \frac{b-a}{2t}}^{p_i}\lp|p_i-p\rp|dp\\
    &= c_a^b\int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}
    \Exp{\lp|\hat{\theta}_t-p\rp|}_p
    dp + \frac{1}{4} \frac{\lp(b-a\rp)^2}{t^2}
  \end{align*}

  Therefore:
  \begin{equation}\label{eq:one_side}
    \frac{E_i}{t} \leq \frac{c_a^b}{b-a}
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}
    \Exp{\lp|\hat{\theta}_t-p\rp|}_p dp + \frac{b-a}{4t^2}
  \end{equation}
  By summing up Equation~(\ref{eq:one_side}) for all $t$ intervals, we get:
  \begin{align*}
    \frac{\sum_{i=0}^{t-1} E_i}{t} &\leq \frac{c_a^b}{b-a} \sum_{i=0}^{t-1}
    \int_{p_i - \frac{b-a}{2t}}^{p_i+ \frac{b-a}{2t}}
    \Exp{\lp|\hat{\theta}_t-p\rp|}_p dp + \frac{b-a}{4t}\\
    &=
    \frac{c_a^b}{b-a} \int_a^b \Exp{\lp|\hat{\theta}_t-p\rp|}_p dp + \frac{b-a}{4t}
  \end{align*}
\end{proof}
