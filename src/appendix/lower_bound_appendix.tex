\section{Lower Bound}
\begin{lemma}\label{l:dkl}
  Let $P=B(p)$ and $Q=B(q)$ be two Bernoulli distributions then
  \[
    \dkl{P}{Q} \leq
    \lp(\frac{1}{p (1-p)} + \frac{1}{q (1-q)} \rp) \frac{(p - q)^2}{2}
  \]

\end{lemma}
\begin{proof}
  We have that
  \(
    \dkl{P}{Q} = p \log (p/q) + (1-p) \log((1-p)/(1-q))
  \).
  Let
  \[
    f(x,y) =
    x \log\left(\frac{x}{y}\right) +
    (1-x) \log\left(\frac{1-x}{1-y}\right)
  \]
  To simplify notation fix $y$ and  let $g(x) = f(x,y)$.  We have
  \begin{align*}
    g'(x) = - \log\lp(\frac{1-x}{1-y}\rp) + \log\lp(\frac{x}{y}\rp),
    \qquad g''(x) = \frac{1}{(1-x)x}
  \end{align*}
  If $x < y$ using Taylor in the interval $[x,y]$ we have for a $\xi \in [x,y]$
  \[
    g(x) = g(y) + g'(y)(y-x) + g''(\xi) (y-x)^2/2 = g''(\xi) (x-y)^2/2.
  \]
  If $x> y$ the using Taylor in the interval $[y,x]$ we get the same
  expression as above.
  Since $g''(x)$ is convex and is minimized at $x_0 = 1/2$ we have that
  if $|x-1/2| < |y-1/2|$ then $g''(\xi) \leq g''(y)$
  else $g''(\xi) \leq g''(x)$.  Therefore,
  \[
    g(x) =
    f(x,y) \leq
    \max(g''(x), g''(y))(x-y)^2/2 \leq  (g''(x) + g''(y)) (x-y)^2/2
  \]
\end{proof}

We are now going to use Lemma~(\ref{l:fano}) to prove the following lemma,
which provides a lower bound for the mean of the expectation of errors
of the estimator.
\begin{lemma}\label{l:fano_application}
  Suppose we choose $t$ Bernoulli distributions $\{P_i\}_{i=0}^{t-1}$
  with the following probabilities:
  \[
    p_i = a+\frac{b-a}{2t} + i \frac{b-a}{t} , i=0, ..., t-1
  \].
  Then:
  $$
  \frac{1}{t} \sum_{i=1}^t \Exp{\lp|\hat{\theta}_t-p_i\rp|}
  \geq \frac{b-a}{2t} \lp(c_1 - \frac{c_2}{t}\rp)
  $$
  where $c_1, c_2 >0$ and $c_1 > \frac{1}{2}$.
\end{lemma}
\begin{proof}
  Without loss of generality, we can assume that $t$ is a multiple of 5.
  For simplicity, we set $R_{p_i}(t) = \Exp{\lp|\hat{\theta}_t-p_i\rp|}$.
  By the choice of $p_i$, we have that $$\lp|p_i - p_j\rp| \geq \frac{b-a}{t}$$,
  for every distinct $i,j$ in the family.
  This means that for the family of $t$ distributions that we picked, the property
  of Lemma~(\ref{l:fano}) is satisfied for $\delta = \frac{b-a}{2t}$.
  Thus, by dividing the $t$ distributions into groups of 5 and applying
  Lemma~(\ref{l:fano}) to each one, we obtain:
  \begin{align}\label{eq:fano}
    \frac{\sum_{k =i}^{i+4}R_{p_i}(t)}{5}
    &\geq
    \frac{b-a}{2t}\lp(1-\frac{I(X;V)+\log 2}{\log n}\rp) \nonumber\\
    &=
    \frac{b-a}{2t}\lp(1- \frac{\log 2}{\log 5} - \frac{I(X;V)}{\log5}\rp) \nonumber\\
    &=
    \frac{b-a}{2t}\lp(c_1 - \frac{I(X;V)}{\log5}\rp)
  \end{align}
  where $c_1 = 1-\frac{\log2}{\log5} > \frac{1}{2}$.
  We are now going to upper bound the mutual information $I(X;V)$ for every
  group of 5 distributions. We denote by $P_i^t$ the distribution on
  vectors with $t$ coordinates,
  where each coordinate is sampled independently from $P_i$.
  Let $U= \{i,i+1,i+2,i+3,i+4\}$ be a family of 5 distributions.
  Using a well known inequality REFERENCE NEEDED HERE:
  \begin{align*}
    I(X;V)
    &\leq
    \frac{1}{5^2}\sum_{\substack{i,j \in U}} \dkl{P_i^t}{P_j^t}\\
    &\leq
    \dkl{P_i^t}{P_{i+4}^t}\\
    &=
    t \dkl{P_i}{P_{i+4}}\\
  \end{align*}
  Using Lemma~\ref{l:dkl} we obtain 
  \begin{align*}
    t \dkl{P_i}{P_{i+4}} &\leq
    t \frac{\lp(p_i - p_{i+4}\rp)^2}{2}\lp(\frac{1}{p_i(1-p_i)} + \frac{1}{p_{i+4}(1-p_{i+4})}\rp)\\
    &\leq
    t\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp) \lp(p_i - p_{i+4}\rp)^2\\
    &=
    t\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp)\lp(\frac{b-a}{2t} +
    i\frac{b-a}{t} - \frac{b-a}{t} -(i+4)\frac{b-a}{t}\rp)^2\\
    &=
    t\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp) \frac{16(b-a)^2}{t^2}\\
    &=
    \frac{16(b-a)^2}{t} \lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp)
  \end{align*}
  So, if we set
  $$c_2 = 16\frac{(b-a)^2}{\log5}\lp(\frac{1}{a(1-a)} + \frac{1}{b(1-b)}\rp)$$
  then by equation~(\ref{eq:fano}) we obtain:
  \begin{equation}\label{eq:fano5}
    \sum_{k =i}^{i+4}R_{p_i}(t) \geq \frac{5(b-a)}{2t}\lp(c_1 - \frac{c_2}{t}\rp)
  \end{equation}
  Inequality~(\ref{eq:fano5}) holds for every group of 5
  distributions. By summing up for all groups:
  \begin{align*}
    \sum_{i=0}^{t-1} R_{p_i}(t) &\geq t \frac{b-a}{2t}\lp(c_1 - \frac{c_2}{t}\rp)\\
    &= \frac{b-a}{2}\lp(c_1 - \frac{c_2}{t}\rp)
  \end{align*}
  which is what we wanted to prove.
\end{proof}
\begin{lemma}\label{l:ratio}
For every $p\in [p_i -\frac{b-a}{2t},p_i + \frac{b-a}{2t}]$,
%\[\Exp{\lp|\hat{\theta}^t-p_i\rp|}_{p_i} \leq c_a^b\Exp{\lp|\hat{\theta}^t-p\rp|}_p + \lp|p - p_i\rp|\]
\[R_{p_i}(t) \leq C_a^b R_{p}(t) +  |p-p_i|\]
where $C_a^b$ is a constant that depends on $a,b$.
\end{lemma}
\begin{proof}
Using the triangle inequality we get
\begin{align*}
R_{p_i}(t) &= \Expnew{p_i}{\lp|\hat{\theta}^t-p_i\rp|}\\
 &\leq \Expnew{p_i}{\lp|\hat{\theta}^t-p\rp|} + \Expnew{p_i}{\lp|p-p_i\rp|}\\
&= \Expnew{p_i}{\lp|\hat{\theta}^t-p\rp|} +\lp|p - p_i\rp|
\end{align*}
It suffices to show that
\[
\Expnew{p_i}{\lp|\hat{\theta}^t-p\rp|} \leq C_a^b \Expnew{p}{\lp|\hat{\theta}^t-p\rp|}
\]
where $C_a^b$ is a constant depending only on $a,b$.
Since the estimator $\hat{\theta}$ receives $t$ samples that are either zero or one, 
we have
\[
\Expnew{p_i}{|\hat{\theta_t} - p|}= \sum_{(y_1,\ldots,y_t)\in
      \{0,1\}^t}|\hat{\theta_t}(y_1,\ldots,y_t) -p| \cdot
    p_i^{\sum_{i=1}^ty_i}(1-p_i)^{t-\sum_{i=1}^ty_i}
\]

Similarly
\[
\Expnew{p}{|\hat{\theta_t} - p|}= \sum_{(y_1,\ldots,y_t)\in
      \{0,1\}^t}|\hat{\theta_t}(y_1,\ldots,y_t) -p| \cdot
    p^{\sum_{i=1}^ty_i}(1-p)^{t-\sum_{i=1}^ty_i}
\]
Since the two expectations are sums with the same number of summands, in order to 
bound the ratio of the two expectations it suffices to 
bound the ratio of each two individual terms of the two sums. 
For each tuple $(y^1,\ldots,y^t)\in\{0,1\}^t$ we have:
\begin{align*}
\frac{|\hat{\theta_t}(y_1,\ldots,y_t) -p| \cdot
    p_i^{\sum_{i=1}^ty_i}(1-p_i)^{t-\sum_{i=1}^ty_i}}
    {|\hat{\theta_t}(y_1,\ldots,y_t) -p| \cdot
    p^{\sum_{i=1}^ty_i}(1-p)^{t-\sum_{i=1}^ty_i}} 
    &= \frac{p_i^{\sum_{i=1}^ty_i}(1-p_i)^{t-\sum_{i=1}^ty_i}}
    {p^{\sum_{i=1}^ty_i}(1-p)^{t-\sum_{i=1}^ty_i}}
\end{align*}
Let $k = \sum_{i=1}^ty_i$.
Since $p \in [p_i -\frac{b-a}{2t},p_i + \frac{b-a}{2t}]$, there is an $\epsilon \in [-\frac{b-a}{2t}, \frac{b-a}{2t}]$ such that $p_i = p - \epsilon$. 
Thus, the above ratio can be written as
\begin{align*}
\lp(\frac{p_i}{p}\rp)^k \lp(\frac{1-p_i}{1-p}\rp)^{t-k} &= 
\lp(\frac{p - \epsilon}{p}\rp)^k \lp(\frac{1-p + \epsilon}{1-p}\rp)^{t-k}\\
&= \lp(1 - \frac{\epsilon}{p}\rp) ^k \lp( 1 + \frac{\epsilon}{1-p}\rp)\\
&\leq \me^{-k\frac{\epsilon}{p}} \me^{(t-k)\frac{\epsilon}{1-p}}\\
&= \me^{-\frac{k\epsilon}{p} + \frac{t\epsilon}{1-p} - \frac{k\epsilon}{1-p}}\\
&\leq \me^{\frac{k|\epsilon|}{p} + \frac{t|\epsilon|}{1-p} + \frac{k|\epsilon|}{1-p}}\\
&\leq \me^{\frac{1}{p} + \frac{2}{1-p}}\\
&\leq \me^{\frac{1}{a} + \frac{2}{1-b}}
\end{align*}
In the above computation, we have used the inequality $1+x \leq \me^x$ and the fact that $|\epsilon|t \leq 1$.
Since this bound holds for all respective terms of the sum, we get
\[
\Expnew{p_i}{\lp|\hat{\theta}^t-p\rp|} \leq \me^{\frac{1}{a} + \frac{2}{1-b}} \Expnew{p}{\lp|\hat{\theta}^t-p\rp|}
\]
\end{proof}


Now, we find an upper bound for the quantity
$\sum_{i=0}^{t-1} R_{p_i}(t)$.
Our goal is to find an upper bound where the coefficient of
$(b-a)/t$ is less than $1/4$.

\begin{lemma}\label{l:upper}
  \[
    \frac{1}{t} \sum_{i=0}^{t-1}
    R_{p_i}(t) \leq
    \frac{c_a^b}{b-a} \int_a^b R_p(t) dp +
    \frac{b-a}{4t}
  \]
\end{lemma}
\begin{proof}
  By Lemma~(\ref{l:cauchy_schwarz}) we get that
  for every $p\in [-(b-a)/{2t} + p_i , p_i + (b-a)/{2t}]$:
  $$R_{p_i}(t) \leq  c_a^bR_p(t) + \lp|p_i - p\rp|$$
  We integrate both sides of the equation with respect to p and get:
  \[
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}} R_{p_i}(t) dp \leq c_a^b
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}
    R_p(t) dp +
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}\lp|p_i - p\rp| dp
  \]
  Hence:
  \begin{align*}
    \frac{b-a}{t} R_{p_i}(t)
    &\leq
    c_a^b\int_{p_i - \frac{b-a}{2t}}^{p_i+ \frac{b-a}{2t}}
    R_p(t) dp +
    2\int_{p_i - \frac{b-a}{2t}}^{p_i}\lp|p_i-p\rp|dp\\
    &= c_a^b\int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}
    R_p(t)
    dp + \frac{1}{4} \frac{\lp(b-a\rp)^2}{t^2}
  \end{align*}

  Therefore:
  \begin{equation}\label{eq:one_side}
    \frac{R_{p_i}(t)}{t} \leq \frac{c_a^b}{b-a}
    \int_{p_i - \frac{b-a}{2t}}^{p_i + \frac{b-a}{2t}}
    R_p(t) dp + \frac{b-a}{4t^2}
  \end{equation}
  By summing up Equation~(\ref{eq:one_side}) for all $t$ intervals, we get:
  \begin{align*}
    \frac{\sum_{i=0}^{t-1} R_{p_i}(t)}{t} &\leq \frac{c_a^b}{b-a} \sum_{i=0}^{t-1}
    \int_{p_i - \frac{b-a}{2t}}^{p_i+ \frac{b-a}{2t}}
    R_p(t) dp + \frac{b-a}{4t}\\
    &=
    \frac{c_a^b}{b-a} \int_a^b R_p(t) dp + \frac{b-a}{4t}
  \end{align*}
\end{proof}
