\section{Limited Information Dynamics with Fast Convergence}\label{app:s:cc_convergence}
We are now going to state and prove a series of lemmas that culminate in
the proof of Theorem~\ref{t:exponential_update_rule}.

\repeatlemma{l:outdatedness_induction}
% \begin{lemma}
%   Let $\rho = \min_i a_i$, and $\pi_{ij}(t) \in \N$ be the most recent round
%   before round $t$, that agent $i$ met agent $j$.
%   If for all $t\geq B$, $t-B \leq \pi_{ij}(t) \leq t-1$ then, for
%   all $t \geq k B$,
%   \(\norm{\infty}{x(t) - x^*} \leq (1-\rho)^k\).
% \end{lemma}
\begin{proof}
  To prove our claim we use induction on $k$. For the induction base $k=1$,
  \begin{align*}
    |x_i(t) - x_i^*|
    =
    |(1-\alpha_i)\sum_{j \in N_i}p_{ij}(x_j(\pi_{ij}(t)) -x_j^*)|
    \leq
    (1-\alpha_i)\sum_{j \in N_i}p_{ij}|x_j(\pi_{ij}(t))-x_j^*|\leq (1-\rho)
  \end{align*}
  Assume that for all $t\geq (k-1)B$ we have that $\norm{\infty}{x(t)-x^*}\leq (1-\rho)^{k-1}$.
  For $k\geq 2$, we again have that
  \[|x_i(t) - x_i^*|\leq (1-\rho)\sum_{j \in N_i}p_{ij}|x_j(\pi_{ij}(t))-x_j^*|\]
  Since $t-B \leq \pi_{ij}(t)$ and $t \geq kB$ we obtain that $\pi_{ij}(t) \geq (k-1)B$.
  As a result, the inductive hypothesis applies, $|x_j(\pi_{ij}(t))-x_j^*| \leq (1-\rho)^{k-1}$
  and $|x_i(t) - x_i^*|\leq (1-\rho)^k$.
\end{proof}

We now turn our attention to
the problem of calculating the size of window $B$, such that with high probability
all agents have outdatedness at most $B$.
We first state a useful fact concerning the coupons collector problem.

\begin{lemma}\label{l:coupons_lemma}
Suppose that the collector picks coupons with different
probabilities, where $n$ is the number of distinct coupons.
Let $w$ be the minimum of these probabilities.
If he selects $\ln n/w+ c/w$ coupons, then:
\[
\Prob{\text{collector hasn't seen all coupons}} \leq \frac{1}{\me^c}
\]
\end{lemma}

%For convenience of reasoning, we will divide the time in "epochs".
%The length of each epoch is $B$, so times $1$ to $B$ belong to the first
%epoch etc.
%The next lemma is a calculation of the appropriate size of $B$.
\begin{lemma}\label{l:coupons}
Let $\pi_{ij}(t)$ be the most recent round before round $t$ that agent $i$ met agent $j$
and $B=2\ln(\frac{nt}{\delta})/\min_{ij}p_{ij}$.
Then with probability at least $1-\delta$, for all $\tau \geq B$ and for all
$i, j \in N_i$\[\tau-B\leq \pi_{ij}(\tau)\leq \tau-1.\]
\end{lemma}
\begin{proof}
For simplicity we denote $w=\min_{ij}p_{ij}$.
Consider an agent $i$ at round $\tau \geq B$ where $B=2\ln(\frac{nt}{\delta})/w$
and assume that there exists an agent $j\in N_i$ such that $\pi_{ij}(\tau)< {\tau-B}$.
Agent $i$ can be viewed as a coupon collector that has buyed $B$ coupons
but has not found the coupon corresponding to agent $j$. Since $N_i<n$ and
$\min_{j \in N_i}p_{ij}\geq w$ by Lemma~\ref{l:coupons_lemma} we have that
\[\Prob{\text{there exists }j\in N_i \text{ s.t. }\pi_{ij}(\tau)< {\tau-B}}\leq \frac{\delta}{nt}\]
The proof follows by a union bound for all agent $i$ and all round $B\leq \tau \leq t$.


%In our setting, coupon $i$ corresponds to the selection of neighbour $i$. Each node is a
%collector and wants to gather all $n-1$ coupons during each epoch.
%Suppose $d = \max_i d_i$ is the maximum degree of the graph.
%Then, if we set  $c = \ln (\frac{nt}{\delta})$ , using Lemma~\ref{l:coupons_lemma}
%we get that a node hasn't seen at least one neighbour after $c/w + \ln d/w$ samples
%with probability at most $\frac{\delta}{nt}$. This means that if we set
%$D = c/w + \ln d/w =  \ln \frac{nt}{\delta}/w +  \ln d/w \geq 2/w\ln\frac{nt}{\delta}$
%when $\delta$ is small enough, then the probability that a specific agent at a specific
%epoch hasn't collected all neighbouring opinions at least once is at most $\frac{\delta}{nt}$.
%By a simple union bound argument, we get that all agents have seen all their neighbours during all epochs
%with probability at least $1 - \delta$.
\end{proof}
%Since all neighbours are picked at least once during each epoch,
%the outdatedness of each agent is at most twice the length of the
%epoch. We now show %Lemma~\ref{l:outdatedness_induction}
%from which we get that bounded outdatedness preserves the fast
%convergence.
%
%Combining this with Lemma~\ref{l:outdatedness_induction} we have
%the following.
By direct application of Lemma~\ref{l:outdatedness_induction} and
Lemma~\ref{l:coupons}, we obtain the following corollary that
will be useful in proving Theorem~\ref{t:exponential_update_rule}.
\begin{corollary}\label{cor:window}
Let $x(t)$ the opinion vector produced by update rule (\ref{alg:cc_upper})
for the instance $I=(P,s,\alpha)$,
then with probability at least $1-\delta$
\[\norm{\infty}{x(t)-x^*} %\leq (1-\rho)^{\frac{t}{2B}}
\leq \exp \lp(-\frac{\rho t\min_{ij}p_{ij}}{2\ln( \frac{nt}{\delta})} \rp)\]
where $\rho = \min_{i\in V}\alpha_i$.
\end{corollary}
\begin{proof}
Let $B=2\ln(\frac{nt}{\delta})/\min_{ij}p_{ij}$. By Lemma~\ref{l:coupons}
we have that with probability at least $1-\delta$, for all $i,j\in N_i$ and
for all $\tau \geq B$, \[\tau -B \leq \pi_{ij}(\tau)  \]
As a result, with probability at least $1-\delta$ the requirements
of Lemma~\ref{l:outdatedness_induction} are satisfied, meaning that
\[\norm{\infty}{x(t)-x^*} \leq (1-\rho)^{\frac{t}{B}}
\leq \exp \lp(-\frac{\rho t\min_{ij}p_{ij}}{2\ln( \frac{nt}{\delta})} \rp)\]
\end{proof}

\noindent We can now prove Theorem~\ref{t:exponential_update_rule} using the previous results.
\repeattheorem{t:exponential_update_rule}
\begin{proof}
Let $u(t) = \norm{\infty}{x(t)-x^*}$ and $w = \min_{ij}p_{ij}$.
From Corollary~\ref{cor:window} we obtain:
\[ \Prob{u(t) >\exp\lp(-\frac{\rho wt}{2\ln( \frac{nt}{\delta})} \rp)} \leq \delta \]
for every probability $\delta \in [0,1]$. Also, since all the
parameters of the problem lie in $[0,1]$, we have
\[\Exp{u(t)|u(t) > r} \leq 1\]
Now, by the conditional expectations identity, we get:
\begin{align*}
\Exp{u(t)} &= \Exp{u(t)|u(t) > r}\Prob{u(t) > r} +\Exp{u(t)|u(t) \leq r}\Prob{u(t) \leq r}\\
&\leq \delta + r
\end{align*}
where $r = \exp \lp(-\frac{\rho wt}{2\ln( \frac{nt}{\delta})}\rp)$.
If we set $\delta = \exp \lp(-\frac{\rho w\sqrt{t}}{2\ln nt}\rp)$, then:
\[
\Exp{u(t)} \leq \exp \lp(-\frac{\rho w\sqrt{t}}{2\ln nt}\rp)
+ \exp \lp(-\frac{\rho wt}{2\ln( \frac{nt}{\delta})}\rp)
\]
We now evaluate $r$ for our choice of probability $\delta$:
\begin{align*}
r
&= \exp \lp(-\frac{\rho wt}{2\ln\lp( \frac{nt}{p}\rp)} \rp)\\
&= \exp \lp(-\frac{\rho wt}{2\ln\lp( \frac{nt}{\exp \lp(-\frac{\rho w\sqrt{t}}{2\ln nt}\rp) }\rp) } \rp) \\
&= \exp \lp(-\frac{\rho wt}{2\ln nt + 2\frac{\rho w\sqrt{t}}{2\ln nt} }\rp)\\
&\leq \exp \lp(-\frac{\rho w t}{4\ln(nt) \sqrt{t}}\rp)\\
&= \exp \lp(-\frac{\rho w\sqrt{t}}{4\ln(nt)}\rp)
\end{align*}

Using the previous calculation, we obtain:
\begin{align*}
\Exp{u(t)} &\leq \exp \lp(-\frac{\rho w\sqrt{t}}{2\ln (nt)}\rp) +
\exp \lp(-\frac{\rho w\sqrt{t}}{4\ln(nt)}\rp) \\
&\leq 2\exp \lp(-\frac{\rho w\sqrt{t}}{4\ln(nt)}\rp)\\
&=2\exp \lp(- \rho  \min_{ij} p_{ij} \frac{\sqrt{t}}{4\ln(nt)} \rp)
\end{align*}
\end{proof}


\begin{example}\label{ex:regret_side_result}
The purpose of this example is to illustrate that 
the update rule~(\ref{alg:cc_upper}) does not ensure the no regret
property. If some agents for various reasons exhibit
irrational or adversarial behavior, agents that adopt update 
rule~(\ref{alg:cc_upper}) may experience regret. That is the reason
that \emph{Row Dependent dynamics} converge exponetially faster that any
\emph{no regret dynamics} incluing the \emph{FTL dynamics}.

Consider the instance of the game of Definition~\ref{d:random_game} consisting
of two agents. Agent $1$ adopts update rule~(\ref{alg:cc_upper}) and
has $s_1=0,\alpha_1=1/2,p_{12}=1$ and agent $2$ plays adversarially. Thus,
$s_2,\alpha_2,p_{21}$ don't need to be specified. By update rule~(\ref{alg:cc_upper}),
$x_1(t)=x_2(t-1)/2$ and thus total disagreement cost that agent $1$ experiences until
round $t$ is 
\begin{equation*}
 \sum_{\tau=0}^t\frac{1}{2}x_1(t)^2+\frac{1}{2}(x_1(t) - x_2(t))^2 =
 \sum_{\tau=0}^t\frac{1}{8}x_2(t-1)^2 + \frac{1}{2}(\frac{1}{2}x_2(t-1)-x_2(t))^2.
\end{equation*}
Since agent $2$ plays adversarially, she selects $x_2(t)=0$ if $t$ is even
and $1$ otherwise. As a result, the total cost that agent $1$ experiences is
$\sum_{\tau=0}^t \frac{1}{2}x_1(t)^2+\frac{1}{2}(x_1(t) - x_2(t))^2 \simeq 3t/8$.
Now agent $1$ regrets for no adopting the fixed opinion $1/3$ during the whole game play.
Selecting $x_1(t)=1/3$ for all $t$, would incur him total disagreement cost
$\sum_{\tau=0}^t\frac{1}{2}(1/3)^2+\frac{1}{2}(1/3 - x_2(t))^2\simeq 7t/36$
which is less than $3t/8$.
\end{example}
